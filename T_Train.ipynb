{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "igMyGnjE9hEp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "RANDOM_SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2HDvhIu9hEr"
      },
      "source": [
        "# Specify each path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9NvZP2Zn9hEy"
      },
      "outputs": [],
      "source": [
        "# Specify data paths\n",
        "dataset = './model/Hand_Point/HandPoint.csv'\n",
        "model_save_path = './model/Hand_Point/HandPoint.hdf5'\n",
        "tflite_save_path = './model/Hand_Point/HandPoint.tflite'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5oMH7x19hEz"
      },
      "source": [
        "# Set number of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "du4kodXL9hEz"
      },
      "outputs": [],
      "source": [
        "# Change training classes if necessary\n",
        "NUM_CLASSES = 26"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjnL0uso9hEz"
      },
      "source": [
        "# Dataset reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QT5ZqtEz9hE0"
      },
      "outputs": [],
      "source": [
        "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QmoKFsp49hE0"
      },
      "outputs": [],
      "source": [
        "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xQU7JTZ_9hE0"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.8, random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "xElG5FoPDQO9",
        "outputId": "2ef372ed-62e3-49c1-ad36-a5b5dc76701a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Classes count\n",
        "counts = np.unique(y_dataset, return_counts=True)\n",
        "df = pd.DataFrame(counts)\n",
        "df.T.plot(kind=\"bar\", stacked=True)\n",
        "# print(counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxK_lETT9hE0"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vHBmUf1t9hE1"
      },
      "outputs": [],
      "source": [
        "use_lstm = False\n",
        "model = None\n",
        "\n",
        "if use_lstm:\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(21 * 2, )),\n",
        "        tf.keras.layers.Reshape((1, 21 * 2), input_shape=(21 * 2, )), \n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.LSTM(44, input_shape=[1, 21 * 2]),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(30, activation='relu'),\n",
        "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "    ])\n",
        "else:\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Input((21 * 2, )),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        tf.keras.layers.Dense(52, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(52, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(21, activation='relu'),\n",
        "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "#tf.keras.utils.plot_model(model, \"my_first_model_with_shape_info.png\", show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypqky9tc9hE1",
        "outputId": "c42f3550-ceee-45b8-d40d-d99fd84a2616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 42)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 52)                2236      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 52)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 52)                2756      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 52)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 21)                1113      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 26)                572       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,677\n",
            "Trainable params: 6,677\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MbMjOflQ9hE1"
      },
      "outputs": [],
      "source": [
        "# Model checkpoint callback\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    model_save_path, verbose=1, save_weights_only=False, save_best_only=True)\n",
        "# Callback for early stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(patience=50, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "c3Dac0M_9hE2"
      },
      "outputs": [],
      "source": [
        "# Model compilation\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XI0j1Iu9hE2"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WirBl-JE9hE3",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 3.2165 - accuracy: 0.0573\n",
            "Epoch 1: val_loss improved from inf to 3.10591, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 3.2118 - accuracy: 0.0593 - val_loss: 3.1059 - val_accuracy: 0.0995\n",
            "Epoch 2/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 3.0723 - accuracy: 0.0971\n",
            "Epoch 2: val_loss improved from 3.10591 to 2.86325, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 3.0386 - accuracy: 0.1099 - val_loss: 2.8633 - val_accuracy: 0.1857\n",
            "Epoch 3/1000\n",
            "19/38 [==============>...............] - ETA: 0s - loss: 2.8896 - accuracy: 0.1480\n",
            "Epoch 3: val_loss improved from 2.86325 to 2.56526, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 2.8123 - accuracy: 0.1701 - val_loss: 2.5653 - val_accuracy: 0.2272\n",
            "Epoch 4/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 2.6293 - accuracy: 0.2365\n",
            "Epoch 4: val_loss improved from 2.56526 to 2.28139, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 2.5700 - accuracy: 0.2472 - val_loss: 2.2814 - val_accuracy: 0.3881\n",
            "Epoch 5/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 2.3720 - accuracy: 0.2865\n",
            "Epoch 5: val_loss improved from 2.28139 to 1.86483, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 2.2874 - accuracy: 0.3053 - val_loss: 1.8648 - val_accuracy: 0.4760\n",
            "Epoch 6/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 2.0345 - accuracy: 0.3557\n",
            "Epoch 6: val_loss improved from 1.86483 to 1.49707, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 1.9654 - accuracy: 0.3729 - val_loss: 1.4971 - val_accuracy: 0.5755\n",
            "Epoch 7/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 1.7783 - accuracy: 0.3956\n",
            "Epoch 7: val_loss improved from 1.49707 to 1.21932, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.7173 - accuracy: 0.4119 - val_loss: 1.2193 - val_accuracy: 0.6551\n",
            "Epoch 8/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 1.5593 - accuracy: 0.4464\n",
            "Epoch 8: val_loss improved from 1.21932 to 1.03689, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.5253 - accuracy: 0.4596 - val_loss: 1.0369 - val_accuracy: 0.6783\n",
            "Epoch 9/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 1.4034 - accuracy: 0.4986\n",
            "Epoch 9: val_loss improved from 1.03689 to 0.89786, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 1.3889 - accuracy: 0.5031 - val_loss: 0.8979 - val_accuracy: 0.7496\n",
            "Epoch 10/1000\n",
            "23/38 [=================>............] - ETA: 0s - loss: 1.3137 - accuracy: 0.5238\n",
            "Epoch 10: val_loss improved from 0.89786 to 0.81228, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 1.2917 - accuracy: 0.5280 - val_loss: 0.8123 - val_accuracy: 0.8076\n",
            "Epoch 11/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 1.2112 - accuracy: 0.5540\n",
            "Epoch 11: val_loss improved from 0.81228 to 0.73587, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 1.2187 - accuracy: 0.5508 - val_loss: 0.7359 - val_accuracy: 0.8507\n",
            "Epoch 12/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 1.1764 - accuracy: 0.5565\n",
            "Epoch 12: val_loss improved from 0.73587 to 0.68487, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 1.1722 - accuracy: 0.5587 - val_loss: 0.6849 - val_accuracy: 0.8358\n",
            "Epoch 13/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 1.1267 - accuracy: 0.5817\n",
            "Epoch 13: val_loss improved from 0.68487 to 0.65325, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 1.1292 - accuracy: 0.5856 - val_loss: 0.6532 - val_accuracy: 0.8375\n",
            "Epoch 14/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 1.0705 - accuracy: 0.6109\n",
            "Epoch 14: val_loss improved from 0.65325 to 0.61482, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 1.0729 - accuracy: 0.6101 - val_loss: 0.6148 - val_accuracy: 0.8740\n",
            "Epoch 15/1000\n",
            "23/38 [=================>............] - ETA: 0s - loss: 1.0385 - accuracy: 0.6175\n",
            "Epoch 15: val_loss improved from 0.61482 to 0.55585, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 1.0258 - accuracy: 0.6251 - val_loss: 0.5558 - val_accuracy: 0.8872\n",
            "Epoch 16/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 1.0235 - accuracy: 0.6057\n",
            "Epoch 16: val_loss improved from 0.55585 to 0.53863, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 1.0360 - accuracy: 0.6027 - val_loss: 0.5386 - val_accuracy: 0.8690\n",
            "Epoch 17/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.9839 - accuracy: 0.6429\n",
            "Epoch 17: val_loss improved from 0.53863 to 0.52144, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9938 - accuracy: 0.6379 - val_loss: 0.5214 - val_accuracy: 0.8640\n",
            "Epoch 18/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.9532 - accuracy: 0.6378\n",
            "Epoch 18: val_loss improved from 0.52144 to 0.48553, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.9382 - accuracy: 0.6491 - val_loss: 0.4855 - val_accuracy: 0.9055\n",
            "Epoch 19/1000\n",
            "23/38 [=================>............] - ETA: 0s - loss: 0.9230 - accuracy: 0.6603\n",
            "Epoch 19: val_loss improved from 0.48553 to 0.46547, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.9404 - accuracy: 0.6578 - val_loss: 0.4655 - val_accuracy: 0.9187\n",
            "Epoch 20/1000\n",
            "23/38 [=================>............] - ETA: 0s - loss: 0.8534 - accuracy: 0.7058\n",
            "Epoch 20: val_loss improved from 0.46547 to 0.43570, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.8610 - accuracy: 0.6918 - val_loss: 0.4357 - val_accuracy: 0.9071\n",
            "Epoch 21/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.8882 - accuracy: 0.6726\n",
            "Epoch 21: val_loss did not improve from 0.43570\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.8843 - accuracy: 0.6740 - val_loss: 0.4388 - val_accuracy: 0.8856\n",
            "Epoch 22/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.8740 - accuracy: 0.6629\n",
            "Epoch 22: val_loss improved from 0.43570 to 0.41069, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8527 - accuracy: 0.6810 - val_loss: 0.4107 - val_accuracy: 0.9104\n",
            "Epoch 23/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.8135 - accuracy: 0.6969\n",
            "Epoch 23: val_loss improved from 0.41069 to 0.39496, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.8235 - accuracy: 0.6981 - val_loss: 0.3950 - val_accuracy: 0.9221\n",
            "Epoch 24/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.8341 - accuracy: 0.6786\n",
            "Epoch 24: val_loss did not improve from 0.39496\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.8293 - accuracy: 0.6922 - val_loss: 0.4146 - val_accuracy: 0.9005\n",
            "Epoch 25/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.8311 - accuracy: 0.6815\n",
            "Epoch 25: val_loss improved from 0.39496 to 0.38879, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.8107 - accuracy: 0.6918 - val_loss: 0.3888 - val_accuracy: 0.9055\n",
            "Epoch 26/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.7957 - accuracy: 0.6988\n",
            "Epoch 26: val_loss improved from 0.38879 to 0.37981, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.8007 - accuracy: 0.6968 - val_loss: 0.3798 - val_accuracy: 0.9204\n",
            "Epoch 27/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.7879 - accuracy: 0.7140\n",
            "Epoch 27: val_loss improved from 0.37981 to 0.36690, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.7871 - accuracy: 0.7159 - val_loss: 0.3669 - val_accuracy: 0.9287\n",
            "Epoch 28/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.7226 - accuracy: 0.7344\n",
            "Epoch 28: val_loss improved from 0.36690 to 0.34921, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.7508 - accuracy: 0.7234 - val_loss: 0.3492 - val_accuracy: 0.9320\n",
            "Epoch 29/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.7537 - accuracy: 0.7284\n",
            "Epoch 29: val_loss improved from 0.34921 to 0.34640, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.7662 - accuracy: 0.7287 - val_loss: 0.3464 - val_accuracy: 0.9353\n",
            "Epoch 30/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.7123 - accuracy: 0.7443\n",
            "Epoch 30: val_loss improved from 0.34640 to 0.32083, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.7156 - accuracy: 0.7453 - val_loss: 0.3208 - val_accuracy: 0.9270\n",
            "Epoch 31/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.7213 - accuracy: 0.7273\n",
            "Epoch 31: val_loss improved from 0.32083 to 0.30539, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.7145 - accuracy: 0.7304 - val_loss: 0.3054 - val_accuracy: 0.9486\n",
            "Epoch 32/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.7477 - accuracy: 0.7216\n",
            "Epoch 32: val_loss did not improve from 0.30539\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.7291 - accuracy: 0.7300 - val_loss: 0.3331 - val_accuracy: 0.9138\n",
            "Epoch 33/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.7258 - accuracy: 0.7344\n",
            "Epoch 33: val_loss improved from 0.30539 to 0.29606, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.7317 - accuracy: 0.7242 - val_loss: 0.2961 - val_accuracy: 0.9519\n",
            "Epoch 34/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.6925 - accuracy: 0.7514\n",
            "Epoch 34: val_loss improved from 0.29606 to 0.29196, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.7075 - accuracy: 0.7441 - val_loss: 0.2920 - val_accuracy: 0.9370\n",
            "Epoch 35/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.7057 - accuracy: 0.7322\n",
            "Epoch 35: val_loss improved from 0.29196 to 0.28546, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.6778 - accuracy: 0.7416 - val_loss: 0.2855 - val_accuracy: 0.9453\n",
            "Epoch 36/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.7021 - accuracy: 0.7429\n",
            "Epoch 36: val_loss did not improve from 0.28546\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.6878 - accuracy: 0.7507 - val_loss: 0.2873 - val_accuracy: 0.9303\n",
            "Epoch 37/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.6518 - accuracy: 0.7664\n",
            "Epoch 37: val_loss improved from 0.28546 to 0.27158, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6631 - accuracy: 0.7632 - val_loss: 0.2716 - val_accuracy: 0.9469\n",
            "Epoch 38/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.6645 - accuracy: 0.7557\n",
            "Epoch 38: val_loss did not improve from 0.27158\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.7470 - val_loss: 0.2760 - val_accuracy: 0.9502\n",
            "Epoch 39/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.6608 - accuracy: 0.7537\n",
            "Epoch 39: val_loss did not improve from 0.27158\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.6747 - accuracy: 0.7449 - val_loss: 0.2773 - val_accuracy: 0.9552\n",
            "Epoch 40/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.6495 - accuracy: 0.7617\n",
            "Epoch 40: val_loss improved from 0.27158 to 0.24810, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6559 - accuracy: 0.7590 - val_loss: 0.2481 - val_accuracy: 0.9635\n",
            "Epoch 41/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.6300 - accuracy: 0.7699\n",
            "Epoch 41: val_loss did not improve from 0.24810\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.6456 - accuracy: 0.7611 - val_loss: 0.2646 - val_accuracy: 0.9569\n",
            "Epoch 42/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.6005 - accuracy: 0.7753\n",
            "Epoch 42: val_loss did not improve from 0.24810\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.6239 - accuracy: 0.7698 - val_loss: 0.2534 - val_accuracy: 0.9619\n",
            "Epoch 43/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.6101 - accuracy: 0.7750\n",
            "Epoch 43: val_loss improved from 0.24810 to 0.23549, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.6057 - accuracy: 0.7789 - val_loss: 0.2355 - val_accuracy: 0.9569\n",
            "Epoch 44/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.6467 - accuracy: 0.7536\n",
            "Epoch 44: val_loss did not improve from 0.23549\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.6420 - accuracy: 0.7661 - val_loss: 0.2519 - val_accuracy: 0.9619\n",
            "Epoch 45/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.6289 - accuracy: 0.7699\n",
            "Epoch 45: val_loss did not improve from 0.23549\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.7727 - val_loss: 0.2448 - val_accuracy: 0.9569\n",
            "Epoch 46/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.5818 - accuracy: 0.7839\n",
            "Epoch 46: val_loss improved from 0.23549 to 0.22120, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5882 - accuracy: 0.7847 - val_loss: 0.2212 - val_accuracy: 0.9569\n",
            "Epoch 47/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.6004 - accuracy: 0.7723\n",
            "Epoch 47: val_loss improved from 0.22120 to 0.22040, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5910 - accuracy: 0.7839 - val_loss: 0.2204 - val_accuracy: 0.9635\n",
            "Epoch 48/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.5995 - accuracy: 0.7884\n",
            "Epoch 48: val_loss did not improve from 0.22040\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.5957 - accuracy: 0.7847 - val_loss: 0.2252 - val_accuracy: 0.9486\n",
            "Epoch 49/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.5671 - accuracy: 0.7891\n",
            "Epoch 49: val_loss improved from 0.22040 to 0.21214, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.5798 - accuracy: 0.7930 - val_loss: 0.2121 - val_accuracy: 0.9602\n",
            "Epoch 50/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.5876 - accuracy: 0.7909\n",
            "Epoch 50: val_loss improved from 0.21214 to 0.20843, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.5849 - accuracy: 0.7914 - val_loss: 0.2084 - val_accuracy: 0.9685\n",
            "Epoch 51/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.5276 - accuracy: 0.8132\n",
            "Epoch 51: val_loss improved from 0.20843 to 0.19474, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.5484 - accuracy: 0.7976 - val_loss: 0.1947 - val_accuracy: 0.9718\n",
            "Epoch 52/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5577 - accuracy: 0.7930\n",
            "Epoch 52: val_loss did not improve from 0.19474\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.5577 - accuracy: 0.7930 - val_loss: 0.1967 - val_accuracy: 0.9751\n",
            "Epoch 53/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.5526 - accuracy: 0.8099\n",
            "Epoch 53: val_loss did not improve from 0.19474\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.5529 - accuracy: 0.8075 - val_loss: 0.2063 - val_accuracy: 0.9602\n",
            "Epoch 54/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5308 - accuracy: 0.8045\n",
            "Epoch 54: val_loss improved from 0.19474 to 0.19227, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5305 - accuracy: 0.8042 - val_loss: 0.1923 - val_accuracy: 0.9619\n",
            "Epoch 55/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.5642 - accuracy: 0.7924\n",
            "Epoch 55: val_loss improved from 0.19227 to 0.18062, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5575 - accuracy: 0.7980 - val_loss: 0.1806 - val_accuracy: 0.9701\n",
            "Epoch 56/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.5520 - accuracy: 0.7876\n",
            "Epoch 56: val_loss did not improve from 0.18062\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.5491 - accuracy: 0.7943 - val_loss: 0.2004 - val_accuracy: 0.9735\n",
            "Epoch 57/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.5529 - accuracy: 0.7990\n",
            "Epoch 57: val_loss did not improve from 0.18062\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.8067 - val_loss: 0.1918 - val_accuracy: 0.9735\n",
            "Epoch 58/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.5566 - accuracy: 0.7865\n",
            "Epoch 58: val_loss did not improve from 0.18062\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7968 - val_loss: 0.1888 - val_accuracy: 0.9652\n",
            "Epoch 59/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.5223 - accuracy: 0.8102\n",
            "Epoch 59: val_loss improved from 0.18062 to 0.17132, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5184 - accuracy: 0.8109 - val_loss: 0.1713 - val_accuracy: 0.9784\n",
            "Epoch 60/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.5234 - accuracy: 0.8125\n",
            "Epoch 60: val_loss did not improve from 0.17132\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.8105 - val_loss: 0.1740 - val_accuracy: 0.9768\n",
            "Epoch 61/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5118 - accuracy: 0.8163\n",
            "Epoch 61: val_loss did not improve from 0.17132\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.8163 - val_loss: 0.1742 - val_accuracy: 0.9718\n",
            "Epoch 62/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5148 - accuracy: 0.8184\n",
            "Epoch 62: val_loss improved from 0.17132 to 0.16649, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.5121 - accuracy: 0.8196 - val_loss: 0.1665 - val_accuracy: 0.9818\n",
            "Epoch 63/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.5025 - accuracy: 0.8177\n",
            "Epoch 63: val_loss did not improve from 0.16649\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.8225 - val_loss: 0.1680 - val_accuracy: 0.9751\n",
            "Epoch 64/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5127 - accuracy: 0.8159\n",
            "Epoch 64: val_loss improved from 0.16649 to 0.15788, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5129 - accuracy: 0.8150 - val_loss: 0.1579 - val_accuracy: 0.9867\n",
            "Epoch 65/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.4920 - accuracy: 0.8281\n",
            "Epoch 65: val_loss did not improve from 0.15788\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.8229 - val_loss: 0.1714 - val_accuracy: 0.9569\n",
            "Epoch 66/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4835 - accuracy: 0.8222\n",
            "Epoch 66: val_loss improved from 0.15788 to 0.15690, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.4835 - accuracy: 0.8225 - val_loss: 0.1569 - val_accuracy: 0.9851\n",
            "Epoch 67/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.4849 - accuracy: 0.8266\n",
            "Epoch 67: val_loss improved from 0.15690 to 0.14535, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4790 - accuracy: 0.8270 - val_loss: 0.1454 - val_accuracy: 0.9867\n",
            "Epoch 68/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.4494 - accuracy: 0.8295\n",
            "Epoch 68: val_loss did not improve from 0.14535\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.8204 - val_loss: 0.1467 - val_accuracy: 0.9834\n",
            "Epoch 69/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.4894 - accuracy: 0.8295\n",
            "Epoch 69: val_loss did not improve from 0.14535\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.8395 - val_loss: 0.1508 - val_accuracy: 0.9818\n",
            "Epoch 70/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.4839 - accuracy: 0.8277\n",
            "Epoch 70: val_loss did not improve from 0.14535\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.8262 - val_loss: 0.1522 - val_accuracy: 0.9818\n",
            "Epoch 71/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.4925 - accuracy: 0.8336\n",
            "Epoch 71: val_loss did not improve from 0.14535\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.8328 - val_loss: 0.1458 - val_accuracy: 0.9818\n",
            "Epoch 72/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.4838 - accuracy: 0.8359\n",
            "Epoch 72: val_loss did not improve from 0.14535\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.8382 - val_loss: 0.1468 - val_accuracy: 0.9834\n",
            "Epoch 73/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.4602 - accuracy: 0.8346\n",
            "Epoch 73: val_loss improved from 0.14535 to 0.13739, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.4535 - accuracy: 0.8370 - val_loss: 0.1374 - val_accuracy: 0.9784\n",
            "Epoch 74/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.4198 - accuracy: 0.8653\n",
            "Epoch 74: val_loss improved from 0.13739 to 0.12786, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.8511 - val_loss: 0.1279 - val_accuracy: 0.9867\n",
            "Epoch 75/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.4642 - accuracy: 0.8297\n",
            "Epoch 75: val_loss did not improve from 0.12786\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.8407 - val_loss: 0.1418 - val_accuracy: 0.9801\n",
            "Epoch 76/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4647 - accuracy: 0.8290\n",
            "Epoch 76: val_loss did not improve from 0.12786\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.8304 - val_loss: 0.1358 - val_accuracy: 0.9884\n",
            "Epoch 77/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4716 - accuracy: 0.8341\n",
            "Epoch 77: val_loss did not improve from 0.12786\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.8341 - val_loss: 0.1394 - val_accuracy: 0.9884\n",
            "Epoch 78/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.4563 - accuracy: 0.8376\n",
            "Epoch 78: val_loss did not improve from 0.12786\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.8358 - val_loss: 0.1297 - val_accuracy: 0.9867\n",
            "Epoch 79/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.4799 - accuracy: 0.8211\n",
            "Epoch 79: val_loss did not improve from 0.12786\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8287 - val_loss: 0.1317 - val_accuracy: 0.9834\n",
            "Epoch 80/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.4481 - accuracy: 0.8355\n",
            "Epoch 80: val_loss improved from 0.12786 to 0.12657, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.4495 - accuracy: 0.8370 - val_loss: 0.1266 - val_accuracy: 0.9784\n",
            "Epoch 81/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.4544 - accuracy: 0.8438\n",
            "Epoch 81: val_loss did not improve from 0.12657\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.8416 - val_loss: 0.1354 - val_accuracy: 0.9834\n",
            "Epoch 82/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.4238 - accuracy: 0.8429\n",
            "Epoch 82: val_loss improved from 0.12657 to 0.11730, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4225 - accuracy: 0.8436 - val_loss: 0.1173 - val_accuracy: 0.9834\n",
            "Epoch 83/1000\n",
            "27/38 [====================>.........] - ETA: 0s - loss: 0.4314 - accuracy: 0.8490\n",
            "Epoch 83: val_loss did not improve from 0.11730\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.8494 - val_loss: 0.1239 - val_accuracy: 0.9818\n",
            "Epoch 84/1000\n",
            "27/38 [====================>.........] - ETA: 0s - loss: 0.4579 - accuracy: 0.8391\n",
            "Epoch 84: val_loss did not improve from 0.11730\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4579 - accuracy: 0.8387 - val_loss: 0.1197 - val_accuracy: 0.9917\n",
            "Epoch 85/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 0.4335 - accuracy: 0.8465\n",
            "Epoch 85: val_loss improved from 0.11730 to 0.11326, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4228 - accuracy: 0.8494 - val_loss: 0.1133 - val_accuracy: 0.9867\n",
            "Epoch 86/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.4509 - accuracy: 0.8383\n",
            "Epoch 86: val_loss did not improve from 0.11326\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.8420 - val_loss: 0.1232 - val_accuracy: 0.9867\n",
            "Epoch 87/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.4123 - accuracy: 0.8601\n",
            "Epoch 87: val_loss did not improve from 0.11326\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.8536 - val_loss: 0.1134 - val_accuracy: 0.9934\n",
            "Epoch 88/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.4064 - accuracy: 0.8571\n",
            "Epoch 88: val_loss did not improve from 0.11326\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.8490 - val_loss: 0.1177 - val_accuracy: 0.9851\n",
            "Epoch 89/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4155 - accuracy: 0.8497\n",
            "Epoch 89: val_loss did not improve from 0.11326\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8494 - val_loss: 0.1169 - val_accuracy: 0.9784\n",
            "Epoch 90/1000\n",
            "19/38 [==============>...............] - ETA: 0s - loss: 0.3938 - accuracy: 0.8569\n",
            "Epoch 90: val_loss improved from 0.11326 to 0.11172, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.3972 - accuracy: 0.8611 - val_loss: 0.1117 - val_accuracy: 0.9867\n",
            "Epoch 91/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.4180 - accuracy: 0.8445\n",
            "Epoch 91: val_loss improved from 0.11172 to 0.10642, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.8523 - val_loss: 0.1064 - val_accuracy: 0.9950\n",
            "Epoch 92/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.3923 - accuracy: 0.8672\n",
            "Epoch 92: val_loss improved from 0.10642 to 0.09272, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.3894 - accuracy: 0.8677 - val_loss: 0.0927 - val_accuracy: 0.9917\n",
            "Epoch 93/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.4296 - accuracy: 0.8461\n",
            "Epoch 93: val_loss did not improve from 0.09272\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8515 - val_loss: 0.1000 - val_accuracy: 0.9900\n",
            "Epoch 94/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.3835 - accuracy: 0.8625\n",
            "Epoch 94: val_loss did not improve from 0.09272\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8611 - val_loss: 0.1006 - val_accuracy: 0.9917\n",
            "Epoch 95/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.4023 - accuracy: 0.8544\n",
            "Epoch 95: val_loss did not improve from 0.09272\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8540 - val_loss: 0.1132 - val_accuracy: 0.9801\n",
            "Epoch 96/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.4124 - accuracy: 0.8594\n",
            "Epoch 96: val_loss did not improve from 0.09272\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8573 - val_loss: 0.1034 - val_accuracy: 0.9917\n",
            "Epoch 97/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.4353 - accuracy: 0.8469\n",
            "Epoch 97: val_loss did not improve from 0.09272\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.8490 - val_loss: 0.1054 - val_accuracy: 0.9950\n",
            "Epoch 98/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8590\n",
            "Epoch 98: val_loss did not improve from 0.09272\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3863 - accuracy: 0.8611 - val_loss: 0.0963 - val_accuracy: 0.9934\n",
            "Epoch 99/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4206 - accuracy: 0.8494\n",
            "Epoch 99: val_loss did not improve from 0.09272\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.8494 - val_loss: 0.1001 - val_accuracy: 0.9834\n",
            "Epoch 100/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3935 - accuracy: 0.8656\n",
            "Epoch 100: val_loss did not improve from 0.09272\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8673 - val_loss: 0.1017 - val_accuracy: 0.9967\n",
            "Epoch 101/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.4203 - accuracy: 0.8516\n",
            "Epoch 101: val_loss did not improve from 0.09272\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8552 - val_loss: 0.0982 - val_accuracy: 0.9950\n",
            "Epoch 102/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8640\n",
            "Epoch 102: val_loss did not improve from 0.09272\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3799 - accuracy: 0.8640 - val_loss: 0.1017 - val_accuracy: 0.9917\n",
            "Epoch 103/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.4368 - accuracy: 0.8344\n",
            "Epoch 103: val_loss did not improve from 0.09272\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8503 - val_loss: 0.0964 - val_accuracy: 0.9917\n",
            "Epoch 104/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8708\n",
            "Epoch 104: val_loss did not improve from 0.09272\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3897 - accuracy: 0.8706 - val_loss: 0.0931 - val_accuracy: 0.9967\n",
            "Epoch 105/1000\n",
            "19/38 [==============>...............] - ETA: 0s - loss: 0.3932 - accuracy: 0.8561\n",
            "Epoch 105: val_loss did not improve from 0.09272\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3815 - accuracy: 0.8656 - val_loss: 0.0989 - val_accuracy: 0.9934\n",
            "Epoch 106/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3795 - accuracy: 0.8732\n",
            "Epoch 106: val_loss did not improve from 0.09272\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3764 - accuracy: 0.8718 - val_loss: 0.0934 - val_accuracy: 0.9967\n",
            "Epoch 107/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3707 - accuracy: 0.8733\n",
            "Epoch 107: val_loss did not improve from 0.09272\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3723 - accuracy: 0.8727 - val_loss: 0.1031 - val_accuracy: 0.9917\n",
            "Epoch 108/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8661\n",
            "Epoch 108: val_loss did not improve from 0.09272\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3902 - accuracy: 0.8640 - val_loss: 0.1115 - val_accuracy: 0.9768\n",
            "Epoch 109/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3852 - accuracy: 0.8572\n",
            "Epoch 109: val_loss improved from 0.09272 to 0.09133, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3829 - accuracy: 0.8590 - val_loss: 0.0913 - val_accuracy: 0.9967\n",
            "Epoch 110/1000\n",
            "19/38 [==============>...............] - ETA: 0s - loss: 0.3733 - accuracy: 0.8594\n",
            "Epoch 110: val_loss improved from 0.09133 to 0.08382, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.3714 - accuracy: 0.8619 - val_loss: 0.0838 - val_accuracy: 0.9917\n",
            "Epoch 111/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.3840 - accuracy: 0.8658\n",
            "Epoch 111: val_loss did not improve from 0.08382\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3740 - accuracy: 0.8702 - val_loss: 0.0908 - val_accuracy: 0.9917\n",
            "Epoch 112/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.3543 - accuracy: 0.8656\n",
            "Epoch 112: val_loss improved from 0.08382 to 0.08332, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.3577 - accuracy: 0.8702 - val_loss: 0.0833 - val_accuracy: 0.9967\n",
            "Epoch 113/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.3377 - accuracy: 0.8787\n",
            "Epoch 113: val_loss did not improve from 0.08332\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3522 - accuracy: 0.8752 - val_loss: 0.0852 - val_accuracy: 0.9917\n",
            "Epoch 114/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.3845 - accuracy: 0.8698\n",
            "Epoch 114: val_loss did not improve from 0.08332\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3663 - accuracy: 0.8772 - val_loss: 0.0864 - val_accuracy: 0.9950\n",
            "Epoch 115/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3866 - accuracy: 0.8623\n",
            "Epoch 115: val_loss did not improve from 0.08332\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.8623 - val_loss: 0.0859 - val_accuracy: 0.9917\n",
            "Epoch 116/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3679 - accuracy: 0.8694\n",
            "Epoch 116: val_loss did not improve from 0.08332\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3667 - accuracy: 0.8702 - val_loss: 0.0848 - val_accuracy: 0.9884\n",
            "Epoch 117/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3609 - accuracy: 0.8750\n",
            "Epoch 117: val_loss improved from 0.08332 to 0.08028, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.3655 - accuracy: 0.8731 - val_loss: 0.0803 - val_accuracy: 0.9934\n",
            "Epoch 118/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.3559 - accuracy: 0.8759\n",
            "Epoch 118: val_loss did not improve from 0.08028\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3548 - accuracy: 0.8760 - val_loss: 0.0811 - val_accuracy: 0.9950\n",
            "Epoch 119/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3606 - accuracy: 0.8660\n",
            "Epoch 119: val_loss did not improve from 0.08028\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3606 - accuracy: 0.8660 - val_loss: 0.0836 - val_accuracy: 0.9967\n",
            "Epoch 120/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3521 - accuracy: 0.8728\n",
            "Epoch 120: val_loss did not improve from 0.08028\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3525 - accuracy: 0.8727 - val_loss: 0.0860 - val_accuracy: 0.9950\n",
            "Epoch 121/1000\n",
            "19/38 [==============>...............] - ETA: 0s - loss: 0.3443 - accuracy: 0.8824\n",
            "Epoch 121: val_loss did not improve from 0.08028\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3501 - accuracy: 0.8797 - val_loss: 0.0877 - val_accuracy: 0.9867\n",
            "Epoch 122/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3275 - accuracy: 0.8837\n",
            "Epoch 122: val_loss improved from 0.08028 to 0.07696, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.3338 - accuracy: 0.8822 - val_loss: 0.0770 - val_accuracy: 0.9900\n",
            "Epoch 123/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3525 - accuracy: 0.8808\n",
            "Epoch 123: val_loss improved from 0.07696 to 0.07330, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3478 - accuracy: 0.8830 - val_loss: 0.0733 - val_accuracy: 0.9900\n",
            "Epoch 124/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3632 - accuracy: 0.8785\n",
            "Epoch 124: val_loss improved from 0.07330 to 0.07048, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.3595 - accuracy: 0.8793 - val_loss: 0.0705 - val_accuracy: 0.9934\n",
            "Epoch 125/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3233 - accuracy: 0.8853\n",
            "Epoch 125: val_loss improved from 0.07048 to 0.06384, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.3275 - accuracy: 0.8847 - val_loss: 0.0638 - val_accuracy: 0.9934\n",
            "Epoch 126/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3482 - accuracy: 0.8758\n",
            "Epoch 126: val_loss did not improve from 0.06384\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3483 - accuracy: 0.8764 - val_loss: 0.0757 - val_accuracy: 0.9917\n",
            "Epoch 127/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3600 - accuracy: 0.8647\n",
            "Epoch 127: val_loss did not improve from 0.06384\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3619 - accuracy: 0.8631 - val_loss: 0.0757 - val_accuracy: 0.9950\n",
            "Epoch 128/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3468 - accuracy: 0.8801\n",
            "Epoch 128: val_loss did not improve from 0.06384\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3444 - accuracy: 0.8818 - val_loss: 0.0695 - val_accuracy: 0.9950\n",
            "Epoch 129/1000\n",
            "29/38 [=====================>........] - ETA: 0s - loss: 0.3494 - accuracy: 0.8782\n",
            "Epoch 129: val_loss did not improve from 0.06384\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.3465 - accuracy: 0.8789 - val_loss: 0.0698 - val_accuracy: 0.9967\n",
            "Epoch 130/1000\n",
            "26/38 [===================>..........] - ETA: 0s - loss: 0.3330 - accuracy: 0.8804\n",
            "Epoch 130: val_loss did not improve from 0.06384\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.3247 - accuracy: 0.8826 - val_loss: 0.0766 - val_accuracy: 0.9900\n",
            "Epoch 131/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 0.3090 - accuracy: 0.8890\n",
            "Epoch 131: val_loss did not improve from 0.06384\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2985 - accuracy: 0.8913 - val_loss: 0.0728 - val_accuracy: 0.9950\n",
            "Epoch 132/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.3284 - accuracy: 0.8830\n",
            "Epoch 132: val_loss did not improve from 0.06384\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3343 - accuracy: 0.8835 - val_loss: 0.0661 - val_accuracy: 0.9917\n",
            "Epoch 133/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.3240 - accuracy: 0.8832\n",
            "Epoch 133: val_loss did not improve from 0.06384\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3225 - accuracy: 0.8859 - val_loss: 0.0653 - val_accuracy: 1.0000\n",
            "Epoch 134/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3302 - accuracy: 0.8897\n",
            "Epoch 134: val_loss did not improve from 0.06384\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3302 - accuracy: 0.8897 - val_loss: 0.0715 - val_accuracy: 0.9884\n",
            "Epoch 135/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3506 - accuracy: 0.8699\n",
            "Epoch 135: val_loss did not improve from 0.06384\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3407 - accuracy: 0.8743 - val_loss: 0.0795 - val_accuracy: 0.9884\n",
            "Epoch 136/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 0.3361 - accuracy: 0.8789\n",
            "Epoch 136: val_loss did not improve from 0.06384\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.3358 - accuracy: 0.8814 - val_loss: 0.0720 - val_accuracy: 0.9934\n",
            "Epoch 137/1000\n",
            "27/38 [====================>.........] - ETA: 0s - loss: 0.3294 - accuracy: 0.8900\n",
            "Epoch 137: val_loss did not improve from 0.06384\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.3259 - accuracy: 0.8897 - val_loss: 0.0752 - val_accuracy: 0.9917\n",
            "Epoch 138/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3291 - accuracy: 0.8859\n",
            "Epoch 138: val_loss did not improve from 0.06384\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.3291 - accuracy: 0.8859 - val_loss: 0.0730 - val_accuracy: 0.9934\n",
            "Epoch 139/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3176 - accuracy: 0.8851\n",
            "Epoch 139: val_loss improved from 0.06384 to 0.06148, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3163 - accuracy: 0.8855 - val_loss: 0.0615 - val_accuracy: 0.9967\n",
            "Epoch 140/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.2923 - accuracy: 0.8984\n",
            "Epoch 140: val_loss improved from 0.06148 to 0.05795, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.3043 - accuracy: 0.8934 - val_loss: 0.0579 - val_accuracy: 0.9983\n",
            "Epoch 141/1000\n",
            "19/38 [==============>...............] - ETA: 0s - loss: 0.3036 - accuracy: 0.8882\n",
            "Epoch 141: val_loss did not improve from 0.05795\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3188 - accuracy: 0.8888 - val_loss: 0.0661 - val_accuracy: 0.9983\n",
            "Epoch 142/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.3071 - accuracy: 0.8922\n",
            "Epoch 142: val_loss did not improve from 0.05795\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3160 - accuracy: 0.8893 - val_loss: 0.0632 - val_accuracy: 0.9967\n",
            "Epoch 143/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3147 - accuracy: 0.8859\n",
            "Epoch 143: val_loss did not improve from 0.05795\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3147 - accuracy: 0.8859 - val_loss: 0.0634 - val_accuracy: 0.9917\n",
            "Epoch 144/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3320 - accuracy: 0.8850\n",
            "Epoch 144: val_loss did not improve from 0.05795\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3315 - accuracy: 0.8835 - val_loss: 0.0762 - val_accuracy: 0.9900\n",
            "Epoch 145/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3107 - accuracy: 0.8961\n",
            "Epoch 145: val_loss did not improve from 0.05795\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3083 - accuracy: 0.8955 - val_loss: 0.0632 - val_accuracy: 0.9917\n",
            "Epoch 146/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2960 - accuracy: 0.8987\n",
            "Epoch 146: val_loss did not improve from 0.05795\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2923 - accuracy: 0.9017 - val_loss: 0.0670 - val_accuracy: 0.9917\n",
            "Epoch 147/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3207 - accuracy: 0.8851\n",
            "Epoch 147: val_loss did not improve from 0.05795\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3207 - accuracy: 0.8851 - val_loss: 0.0681 - val_accuracy: 1.0000\n",
            "Epoch 148/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3074 - accuracy: 0.8925\n",
            "Epoch 148: val_loss did not improve from 0.05795\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3094 - accuracy: 0.8901 - val_loss: 0.0601 - val_accuracy: 0.9950\n",
            "Epoch 149/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3041 - accuracy: 0.8933\n",
            "Epoch 149: val_loss did not improve from 0.05795\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3070 - accuracy: 0.8913 - val_loss: 0.0677 - val_accuracy: 0.9950\n",
            "Epoch 150/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.3424 - accuracy: 0.8724\n",
            "Epoch 150: val_loss did not improve from 0.05795\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8760 - val_loss: 0.0694 - val_accuracy: 0.9950\n",
            "Epoch 151/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2980 - accuracy: 0.8968\n",
            "Epoch 151: val_loss did not improve from 0.05795\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2961 - accuracy: 0.8996 - val_loss: 0.0595 - val_accuracy: 0.9967\n",
            "Epoch 152/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3262 - accuracy: 0.8879\n",
            "Epoch 152: val_loss did not improve from 0.05795\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3223 - accuracy: 0.8888 - val_loss: 0.0640 - val_accuracy: 0.9917\n",
            "Epoch 153/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2958 - accuracy: 0.8971\n",
            "Epoch 153: val_loss did not improve from 0.05795\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2958 - accuracy: 0.8971 - val_loss: 0.0603 - val_accuracy: 0.9950\n",
            "Epoch 154/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3293 - accuracy: 0.8826\n",
            "Epoch 154: val_loss did not improve from 0.05795\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3293 - accuracy: 0.8826 - val_loss: 0.0699 - val_accuracy: 0.9900\n",
            "Epoch 155/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.3062 - accuracy: 0.8906\n",
            "Epoch 155: val_loss improved from 0.05795 to 0.05705, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2865 - accuracy: 0.9009 - val_loss: 0.0571 - val_accuracy: 0.9934\n",
            "Epoch 156/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2963 - accuracy: 0.8922\n",
            "Epoch 156: val_loss did not improve from 0.05705\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2963 - accuracy: 0.8922 - val_loss: 0.0571 - val_accuracy: 0.9983\n",
            "Epoch 157/1000\n",
            "27/38 [====================>.........] - ETA: 0s - loss: 0.3159 - accuracy: 0.8906\n",
            "Epoch 157: val_loss did not improve from 0.05705\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3251 - accuracy: 0.8913 - val_loss: 0.0614 - val_accuracy: 0.9917\n",
            "Epoch 158/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2891 - accuracy: 0.9020\n",
            "Epoch 158: val_loss did not improve from 0.05705\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2938 - accuracy: 0.9005 - val_loss: 0.0652 - val_accuracy: 0.9818\n",
            "Epoch 159/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2907 - accuracy: 0.9012\n",
            "Epoch 159: val_loss improved from 0.05705 to 0.05666, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.2926 - accuracy: 0.9017 - val_loss: 0.0567 - val_accuracy: 0.9934\n",
            "Epoch 160/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.3232 - accuracy: 0.8967\n",
            "Epoch 160: val_loss improved from 0.05666 to 0.05467, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 1s 19ms/step - loss: 0.3178 - accuracy: 0.8980 - val_loss: 0.0547 - val_accuracy: 0.9967\n",
            "Epoch 161/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.3085 - accuracy: 0.8911\n",
            "Epoch 161: val_loss did not improve from 0.05467\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3016 - accuracy: 0.8946 - val_loss: 0.0575 - val_accuracy: 0.9967\n",
            "Epoch 162/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.2939 - accuracy: 0.9028\n",
            "Epoch 162: val_loss did not improve from 0.05467\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2892 - accuracy: 0.9021 - val_loss: 0.0558 - val_accuracy: 0.9934\n",
            "Epoch 163/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2978 - accuracy: 0.8998\n",
            "Epoch 163: val_loss did not improve from 0.05467\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2934 - accuracy: 0.9005 - val_loss: 0.0562 - val_accuracy: 0.9917\n",
            "Epoch 164/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2863 - accuracy: 0.9040\n",
            "Epoch 164: val_loss improved from 0.05467 to 0.05218, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.2893 - accuracy: 0.9046 - val_loss: 0.0522 - val_accuracy: 0.9983\n",
            "Epoch 165/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.2761 - accuracy: 0.9062\n",
            "Epoch 165: val_loss improved from 0.05218 to 0.05041, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.2779 - accuracy: 0.9067 - val_loss: 0.0504 - val_accuracy: 0.9967\n",
            "Epoch 166/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3137 - accuracy: 0.8915\n",
            "Epoch 166: val_loss did not improve from 0.05041\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3169 - accuracy: 0.8913 - val_loss: 0.0644 - val_accuracy: 0.9934\n",
            "Epoch 167/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2850 - accuracy: 0.9071\n",
            "Epoch 167: val_loss did not improve from 0.05041\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2855 - accuracy: 0.9083 - val_loss: 0.0630 - val_accuracy: 0.9967\n",
            "Epoch 168/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.2936 - accuracy: 0.8955\n",
            "Epoch 168: val_loss did not improve from 0.05041\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2990 - accuracy: 0.8967 - val_loss: 0.0609 - val_accuracy: 0.9934\n",
            "Epoch 169/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2904 - accuracy: 0.8969\n",
            "Epoch 169: val_loss did not improve from 0.05041\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2849 - accuracy: 0.8992 - val_loss: 0.0533 - val_accuracy: 0.9950\n",
            "Epoch 170/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3020 - accuracy: 0.8920\n",
            "Epoch 170: val_loss did not improve from 0.05041\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2974 - accuracy: 0.8959 - val_loss: 0.0515 - val_accuracy: 0.9950\n",
            "Epoch 171/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.2569 - accuracy: 0.9146\n",
            "Epoch 171: val_loss did not improve from 0.05041\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2634 - accuracy: 0.9117 - val_loss: 0.0558 - val_accuracy: 0.9851\n",
            "Epoch 172/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2483 - accuracy: 0.9152\n",
            "Epoch 172: val_loss did not improve from 0.05041\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2513 - accuracy: 0.9150 - val_loss: 0.0618 - val_accuracy: 0.9967\n",
            "Epoch 173/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.2705 - accuracy: 0.9038\n",
            "Epoch 173: val_loss did not improve from 0.05041\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2893 - accuracy: 0.8971 - val_loss: 0.0507 - val_accuracy: 0.9950\n",
            "Epoch 174/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2642 - accuracy: 0.9058\n",
            "Epoch 174: val_loss did not improve from 0.05041\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2615 - accuracy: 0.9058 - val_loss: 0.0564 - val_accuracy: 0.9950\n",
            "Epoch 175/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3114 - accuracy: 0.8923\n",
            "Epoch 175: val_loss improved from 0.05041 to 0.04647, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.3097 - accuracy: 0.8934 - val_loss: 0.0465 - val_accuracy: 0.9967\n",
            "Epoch 176/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.2888 - accuracy: 0.8970\n",
            "Epoch 176: val_loss did not improve from 0.04647\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2933 - accuracy: 0.8963 - val_loss: 0.0584 - val_accuracy: 0.9950\n",
            "Epoch 177/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2980 - accuracy: 0.8939\n",
            "Epoch 177: val_loss did not improve from 0.04647\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2974 - accuracy: 0.8934 - val_loss: 0.0519 - val_accuracy: 0.9917\n",
            "Epoch 178/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2673 - accuracy: 0.9115\n",
            "Epoch 178: val_loss did not improve from 0.04647\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2726 - accuracy: 0.9088 - val_loss: 0.0513 - val_accuracy: 0.9967\n",
            "Epoch 179/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2744 - accuracy: 0.9058\n",
            "Epoch 179: val_loss did not improve from 0.04647\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2741 - accuracy: 0.9058 - val_loss: 0.0495 - val_accuracy: 0.9934\n",
            "Epoch 180/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2927 - accuracy: 0.8999\n",
            "Epoch 180: val_loss did not improve from 0.04647\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2920 - accuracy: 0.9000 - val_loss: 0.0634 - val_accuracy: 0.9884\n",
            "Epoch 181/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2954 - accuracy: 0.8978\n",
            "Epoch 181: val_loss did not improve from 0.04647\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2875 - accuracy: 0.9000 - val_loss: 0.0582 - val_accuracy: 0.9900\n",
            "Epoch 182/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2867 - accuracy: 0.8954\n",
            "Epoch 182: val_loss did not improve from 0.04647\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2848 - accuracy: 0.8976 - val_loss: 0.0486 - val_accuracy: 0.9950\n",
            "Epoch 183/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2789 - accuracy: 0.9032\n",
            "Epoch 183: val_loss did not improve from 0.04647\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2806 - accuracy: 0.9038 - val_loss: 0.0484 - val_accuracy: 0.9967\n",
            "Epoch 184/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2687 - accuracy: 0.9084\n",
            "Epoch 184: val_loss did not improve from 0.04647\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2714 - accuracy: 0.9071 - val_loss: 0.0557 - val_accuracy: 0.9950\n",
            "Epoch 185/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2836 - accuracy: 0.8952\n",
            "Epoch 185: val_loss did not improve from 0.04647\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2895 - accuracy: 0.8938 - val_loss: 0.0532 - val_accuracy: 0.9967\n",
            "Epoch 186/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2619 - accuracy: 0.9128\n",
            "Epoch 186: val_loss did not improve from 0.04647\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2614 - accuracy: 0.9117 - val_loss: 0.0525 - val_accuracy: 0.9917\n",
            "Epoch 187/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2894 - accuracy: 0.9021\n",
            "Epoch 187: val_loss did not improve from 0.04647\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2894 - accuracy: 0.9021 - val_loss: 0.0516 - val_accuracy: 0.9983\n",
            "Epoch 188/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2792 - accuracy: 0.9034\n",
            "Epoch 188: val_loss did not improve from 0.04647\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2782 - accuracy: 0.9038 - val_loss: 0.0524 - val_accuracy: 0.9917\n",
            "Epoch 189/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2687 - accuracy: 0.9085\n",
            "Epoch 189: val_loss did not improve from 0.04647\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2681 - accuracy: 0.9079 - val_loss: 0.0614 - val_accuracy: 0.9751\n",
            "Epoch 190/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2571 - accuracy: 0.9084\n",
            "Epoch 190: val_loss did not improve from 0.04647\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2542 - accuracy: 0.9096 - val_loss: 0.0562 - val_accuracy: 0.9851\n",
            "Epoch 191/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.2822 - accuracy: 0.9078\n",
            "Epoch 191: val_loss did not improve from 0.04647\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2842 - accuracy: 0.9046 - val_loss: 0.0489 - val_accuracy: 0.9934\n",
            "Epoch 192/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2526 - accuracy: 0.9094\n",
            "Epoch 192: val_loss did not improve from 0.04647\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2646 - accuracy: 0.9063 - val_loss: 0.0472 - val_accuracy: 0.9967\n",
            "Epoch 193/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2657 - accuracy: 0.9040\n",
            "Epoch 193: val_loss did not improve from 0.04647\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2696 - accuracy: 0.9038 - val_loss: 0.0505 - val_accuracy: 0.9950\n",
            "Epoch 194/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2694 - accuracy: 0.9094\n",
            "Epoch 194: val_loss did not improve from 0.04647\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2644 - accuracy: 0.9112 - val_loss: 0.0498 - val_accuracy: 0.9950\n",
            "Epoch 195/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2362 - accuracy: 0.9182\n",
            "Epoch 195: val_loss improved from 0.04647 to 0.04588, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2378 - accuracy: 0.9162 - val_loss: 0.0459 - val_accuracy: 0.9967\n",
            "Epoch 196/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.2582 - accuracy: 0.9041\n",
            "Epoch 196: val_loss did not improve from 0.04588\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2494 - accuracy: 0.9121 - val_loss: 0.0496 - val_accuracy: 0.9967\n",
            "Epoch 197/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2417 - accuracy: 0.9196\n",
            "Epoch 197: val_loss did not improve from 0.04588\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2430 - accuracy: 0.9204 - val_loss: 0.0524 - val_accuracy: 0.9917\n",
            "Epoch 198/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2532 - accuracy: 0.9159\n",
            "Epoch 198: val_loss improved from 0.04588 to 0.04504, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2511 - accuracy: 0.9179 - val_loss: 0.0450 - val_accuracy: 0.9967\n",
            "Epoch 199/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2432 - accuracy: 0.9148\n",
            "Epoch 199: val_loss did not improve from 0.04504\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2470 - accuracy: 0.9121 - val_loss: 0.0512 - val_accuracy: 0.9900\n",
            "Epoch 200/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2840 - accuracy: 0.9085\n",
            "Epoch 200: val_loss improved from 0.04504 to 0.04301, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2826 - accuracy: 0.9092 - val_loss: 0.0430 - val_accuracy: 0.9983\n",
            "Epoch 201/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2777 - accuracy: 0.9058\n",
            "Epoch 201: val_loss did not improve from 0.04301\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2778 - accuracy: 0.9058 - val_loss: 0.0529 - val_accuracy: 0.9950\n",
            "Epoch 202/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2896 - accuracy: 0.9015\n",
            "Epoch 202: val_loss did not improve from 0.04301\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2865 - accuracy: 0.9017 - val_loss: 0.0439 - val_accuracy: 0.9983\n",
            "Epoch 203/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2893 - accuracy: 0.8991\n",
            "Epoch 203: val_loss did not improve from 0.04301\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2855 - accuracy: 0.9009 - val_loss: 0.0503 - val_accuracy: 0.9950\n",
            "Epoch 204/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2408 - accuracy: 0.9191\n",
            "Epoch 204: val_loss did not improve from 0.04301\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2408 - accuracy: 0.9191 - val_loss: 0.0472 - val_accuracy: 0.9967\n",
            "Epoch 205/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.2761 - accuracy: 0.9067\n",
            "Epoch 205: val_loss did not improve from 0.04301\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2782 - accuracy: 0.9071 - val_loss: 0.0557 - val_accuracy: 0.9917\n",
            "Epoch 206/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2468 - accuracy: 0.9223\n",
            "Epoch 206: val_loss did not improve from 0.04301\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2496 - accuracy: 0.9224 - val_loss: 0.0551 - val_accuracy: 0.9884\n",
            "Epoch 207/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.2385 - accuracy: 0.9234\n",
            "Epoch 207: val_loss improved from 0.04301 to 0.04164, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.2441 - accuracy: 0.9208 - val_loss: 0.0416 - val_accuracy: 0.9950\n",
            "Epoch 208/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2488 - accuracy: 0.9104\n",
            "Epoch 208: val_loss did not improve from 0.04164\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2488 - accuracy: 0.9108 - val_loss: 0.0454 - val_accuracy: 0.9950\n",
            "Epoch 209/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2826 - accuracy: 0.9022\n",
            "Epoch 209: val_loss did not improve from 0.04164\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2767 - accuracy: 0.9046 - val_loss: 0.0549 - val_accuracy: 0.9934\n",
            "Epoch 210/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2661 - accuracy: 0.9119\n",
            "Epoch 210: val_loss did not improve from 0.04164\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2553 - accuracy: 0.9154 - val_loss: 0.0500 - val_accuracy: 0.9950\n",
            "Epoch 211/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2462 - accuracy: 0.9147\n",
            "Epoch 211: val_loss improved from 0.04164 to 0.03742, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2417 - accuracy: 0.9175 - val_loss: 0.0374 - val_accuracy: 1.0000\n",
            "Epoch 212/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2518 - accuracy: 0.9054\n",
            "Epoch 212: val_loss did not improve from 0.03742\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2474 - accuracy: 0.9079 - val_loss: 0.0442 - val_accuracy: 0.9967\n",
            "Epoch 213/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2441 - accuracy: 0.9167\n",
            "Epoch 213: val_loss did not improve from 0.03742\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2493 - accuracy: 0.9141 - val_loss: 0.0409 - val_accuracy: 0.9950\n",
            "Epoch 214/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2567 - accuracy: 0.9136\n",
            "Epoch 214: val_loss did not improve from 0.03742\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2531 - accuracy: 0.9146 - val_loss: 0.0485 - val_accuracy: 0.9917\n",
            "Epoch 215/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2467 - accuracy: 0.9117\n",
            "Epoch 215: val_loss did not improve from 0.03742\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2467 - accuracy: 0.9117 - val_loss: 0.0545 - val_accuracy: 0.9900\n",
            "Epoch 216/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2426 - accuracy: 0.9167\n",
            "Epoch 216: val_loss did not improve from 0.03742\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2457 - accuracy: 0.9162 - val_loss: 0.0463 - val_accuracy: 0.9917\n",
            "Epoch 217/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2368 - accuracy: 0.9177\n",
            "Epoch 217: val_loss did not improve from 0.03742\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2340 - accuracy: 0.9195 - val_loss: 0.0456 - val_accuracy: 0.9950\n",
            "Epoch 218/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2294 - accuracy: 0.9241\n",
            "Epoch 218: val_loss did not improve from 0.03742\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2314 - accuracy: 0.9237 - val_loss: 0.0422 - val_accuracy: 0.9983\n",
            "Epoch 219/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2430 - accuracy: 0.9168\n",
            "Epoch 219: val_loss did not improve from 0.03742\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2433 - accuracy: 0.9166 - val_loss: 0.0435 - val_accuracy: 0.9983\n",
            "Epoch 220/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2388 - accuracy: 0.9187\n",
            "Epoch 220: val_loss did not improve from 0.03742\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2373 - accuracy: 0.9187 - val_loss: 0.0420 - val_accuracy: 0.9983\n",
            "Epoch 221/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2297 - accuracy: 0.9205\n",
            "Epoch 221: val_loss improved from 0.03742 to 0.03646, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2327 - accuracy: 0.9208 - val_loss: 0.0365 - val_accuracy: 1.0000\n",
            "Epoch 222/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2266 - accuracy: 0.9219\n",
            "Epoch 222: val_loss did not improve from 0.03646\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2274 - accuracy: 0.9204 - val_loss: 0.0523 - val_accuracy: 0.9900\n",
            "Epoch 223/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2499 - accuracy: 0.9149\n",
            "Epoch 223: val_loss did not improve from 0.03646\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2527 - accuracy: 0.9137 - val_loss: 0.0410 - val_accuracy: 0.9983\n",
            "Epoch 224/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2569 - accuracy: 0.9187\n",
            "Epoch 224: val_loss did not improve from 0.03646\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2516 - accuracy: 0.9208 - val_loss: 0.0388 - val_accuracy: 0.9967\n",
            "Epoch 225/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2381 - accuracy: 0.9188\n",
            "Epoch 225: val_loss did not improve from 0.03646\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2397 - accuracy: 0.9195 - val_loss: 0.0467 - val_accuracy: 0.9950\n",
            "Epoch 226/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2306 - accuracy: 0.9249\n",
            "Epoch 226: val_loss did not improve from 0.03646\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2330 - accuracy: 0.9237 - val_loss: 0.0369 - val_accuracy: 0.9950\n",
            "Epoch 227/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2352 - accuracy: 0.9165\n",
            "Epoch 227: val_loss improved from 0.03646 to 0.03442, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2387 - accuracy: 0.9158 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
            "Epoch 228/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.2504 - accuracy: 0.9199\n",
            "Epoch 228: val_loss did not improve from 0.03442\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2501 - accuracy: 0.9200 - val_loss: 0.0492 - val_accuracy: 0.9917\n",
            "Epoch 229/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2424 - accuracy: 0.9133\n",
            "Epoch 229: val_loss did not improve from 0.03442\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2424 - accuracy: 0.9133 - val_loss: 0.0416 - val_accuracy: 1.0000\n",
            "Epoch 230/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2261 - accuracy: 0.9236\n",
            "Epoch 230: val_loss did not improve from 0.03442\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2262 - accuracy: 0.9233 - val_loss: 0.0421 - val_accuracy: 0.9967\n",
            "Epoch 231/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2186 - accuracy: 0.9269\n",
            "Epoch 231: val_loss did not improve from 0.03442\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2213 - accuracy: 0.9266 - val_loss: 0.0351 - val_accuracy: 0.9967\n",
            "Epoch 232/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2362 - accuracy: 0.9141\n",
            "Epoch 232: val_loss did not improve from 0.03442\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2345 - accuracy: 0.9154 - val_loss: 0.0480 - val_accuracy: 0.9950\n",
            "Epoch 233/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2410 - accuracy: 0.9141\n",
            "Epoch 233: val_loss did not improve from 0.03442\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2422 - accuracy: 0.9137 - val_loss: 0.0451 - val_accuracy: 0.9967\n",
            "Epoch 234/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2320 - accuracy: 0.9233\n",
            "Epoch 234: val_loss did not improve from 0.03442\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2314 - accuracy: 0.9237 - val_loss: 0.0372 - val_accuracy: 0.9950\n",
            "Epoch 235/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2285 - accuracy: 0.9265\n",
            "Epoch 235: val_loss did not improve from 0.03442\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2254 - accuracy: 0.9270 - val_loss: 0.0390 - val_accuracy: 0.9967\n",
            "Epoch 236/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2109 - accuracy: 0.9299\n",
            "Epoch 236: val_loss did not improve from 0.03442\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2162 - accuracy: 0.9282 - val_loss: 0.0352 - val_accuracy: 0.9967\n",
            "Epoch 237/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2441 - accuracy: 0.9164\n",
            "Epoch 237: val_loss did not improve from 0.03442\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2406 - accuracy: 0.9162 - val_loss: 0.0418 - val_accuracy: 0.9950\n",
            "Epoch 238/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2424 - accuracy: 0.9141\n",
            "Epoch 238: val_loss improved from 0.03442 to 0.03339, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2422 - accuracy: 0.9141 - val_loss: 0.0334 - val_accuracy: 0.9983\n",
            "Epoch 239/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2262 - accuracy: 0.9259\n",
            "Epoch 239: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2260 - accuracy: 0.9253 - val_loss: 0.0440 - val_accuracy: 0.9934\n",
            "Epoch 240/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2316 - accuracy: 0.9152\n",
            "Epoch 240: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2407 - accuracy: 0.9121 - val_loss: 0.0399 - val_accuracy: 0.9967\n",
            "Epoch 241/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2469 - accuracy: 0.9149\n",
            "Epoch 241: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2466 - accuracy: 0.9166 - val_loss: 0.0395 - val_accuracy: 0.9967\n",
            "Epoch 242/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2306 - accuracy: 0.9187\n",
            "Epoch 242: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2226 - accuracy: 0.9220 - val_loss: 0.0363 - val_accuracy: 0.9950\n",
            "Epoch 243/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2198 - accuracy: 0.9214\n",
            "Epoch 243: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2165 - accuracy: 0.9233 - val_loss: 0.0395 - val_accuracy: 0.9967\n",
            "Epoch 244/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.2234 - accuracy: 0.9229\n",
            "Epoch 244: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2171 - accuracy: 0.9245 - val_loss: 0.0422 - val_accuracy: 0.9900\n",
            "Epoch 245/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2359 - accuracy: 0.9238\n",
            "Epoch 245: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2321 - accuracy: 0.9208 - val_loss: 0.0388 - val_accuracy: 0.9983\n",
            "Epoch 246/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.2294 - accuracy: 0.9194\n",
            "Epoch 246: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2335 - accuracy: 0.9170 - val_loss: 0.0408 - val_accuracy: 0.9967\n",
            "Epoch 247/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2406 - accuracy: 0.9193\n",
            "Epoch 247: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2364 - accuracy: 0.9212 - val_loss: 0.0396 - val_accuracy: 0.9967\n",
            "Epoch 248/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2276 - accuracy: 0.9245\n",
            "Epoch 248: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2278 - accuracy: 0.9249 - val_loss: 0.0360 - val_accuracy: 0.9950\n",
            "Epoch 249/1000\n",
            "27/38 [====================>.........] - ETA: 0s - loss: 0.1921 - accuracy: 0.9317\n",
            "Epoch 249: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2013 - accuracy: 0.9274 - val_loss: 0.0427 - val_accuracy: 0.9884\n",
            "Epoch 250/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2233 - accuracy: 0.9253\n",
            "Epoch 250: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2281 - accuracy: 0.9233 - val_loss: 0.0351 - val_accuracy: 1.0000\n",
            "Epoch 251/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.2177 - accuracy: 0.9268\n",
            "Epoch 251: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2199 - accuracy: 0.9249 - val_loss: 0.0444 - val_accuracy: 0.9917\n",
            "Epoch 252/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2330 - accuracy: 0.9242\n",
            "Epoch 252: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2367 - accuracy: 0.9229 - val_loss: 0.0416 - val_accuracy: 0.9900\n",
            "Epoch 253/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2099 - accuracy: 0.9295\n",
            "Epoch 253: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2144 - accuracy: 0.9274 - val_loss: 0.0371 - val_accuracy: 0.9983\n",
            "Epoch 254/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2044 - accuracy: 0.9297\n",
            "Epoch 254: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2060 - accuracy: 0.9287 - val_loss: 0.0433 - val_accuracy: 0.9967\n",
            "Epoch 255/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2551 - accuracy: 0.9162\n",
            "Epoch 255: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2487 - accuracy: 0.9179 - val_loss: 0.0384 - val_accuracy: 0.9934\n",
            "Epoch 256/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2208 - accuracy: 0.9266\n",
            "Epoch 256: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2220 - accuracy: 0.9253 - val_loss: 0.0409 - val_accuracy: 0.9934\n",
            "Epoch 257/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2250 - accuracy: 0.9266\n",
            "Epoch 257: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2205 - accuracy: 0.9274 - val_loss: 0.0372 - val_accuracy: 0.9950\n",
            "Epoch 258/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2186 - accuracy: 0.9241\n",
            "Epoch 258: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2205 - accuracy: 0.9220 - val_loss: 0.0492 - val_accuracy: 0.9950\n",
            "Epoch 259/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2196 - accuracy: 0.9284\n",
            "Epoch 259: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2206 - accuracy: 0.9270 - val_loss: 0.0383 - val_accuracy: 0.9967\n",
            "Epoch 260/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2081 - accuracy: 0.9214\n",
            "Epoch 260: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2142 - accuracy: 0.9191 - val_loss: 0.0382 - val_accuracy: 0.9934\n",
            "Epoch 261/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2160 - accuracy: 0.9253\n",
            "Epoch 261: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2155 - accuracy: 0.9249 - val_loss: 0.0399 - val_accuracy: 0.9917\n",
            "Epoch 262/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2170 - accuracy: 0.9315\n",
            "Epoch 262: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2175 - accuracy: 0.9316 - val_loss: 0.0397 - val_accuracy: 0.9950\n",
            "Epoch 263/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2128 - accuracy: 0.9247\n",
            "Epoch 263: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2100 - accuracy: 0.9249 - val_loss: 0.0355 - val_accuracy: 0.9967\n",
            "Epoch 264/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2102 - accuracy: 0.9271\n",
            "Epoch 264: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2085 - accuracy: 0.9291 - val_loss: 0.0370 - val_accuracy: 0.9934\n",
            "Epoch 265/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2210 - accuracy: 0.9278\n",
            "Epoch 265: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2264 - accuracy: 0.9266 - val_loss: 0.0359 - val_accuracy: 0.9967\n",
            "Epoch 266/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2153 - accuracy: 0.9249\n",
            "Epoch 266: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2150 - accuracy: 0.9245 - val_loss: 0.0372 - val_accuracy: 0.9983\n",
            "Epoch 267/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2124 - accuracy: 0.9286\n",
            "Epoch 267: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2181 - accuracy: 0.9262 - val_loss: 0.0432 - val_accuracy: 0.9917\n",
            "Epoch 268/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2140 - accuracy: 0.9297\n",
            "Epoch 268: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2168 - accuracy: 0.9270 - val_loss: 0.0430 - val_accuracy: 0.9967\n",
            "Epoch 269/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2246 - accuracy: 0.9251\n",
            "Epoch 269: val_loss did not improve from 0.03339\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2254 - accuracy: 0.9253 - val_loss: 0.0403 - val_accuracy: 0.9950\n",
            "Epoch 270/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1958 - accuracy: 0.9339\n",
            "Epoch 270: val_loss improved from 0.03339 to 0.03317, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1955 - accuracy: 0.9332 - val_loss: 0.0332 - val_accuracy: 0.9967\n",
            "Epoch 271/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.2077 - accuracy: 0.9326\n",
            "Epoch 271: val_loss improved from 0.03317 to 0.03195, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2074 - accuracy: 0.9324 - val_loss: 0.0320 - val_accuracy: 0.9967\n",
            "Epoch 272/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2061 - accuracy: 0.9290\n",
            "Epoch 272: val_loss did not improve from 0.03195\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2162 - accuracy: 0.9266 - val_loss: 0.0340 - val_accuracy: 0.9967\n",
            "Epoch 273/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2141 - accuracy: 0.9288\n",
            "Epoch 273: val_loss did not improve from 0.03195\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2191 - accuracy: 0.9287 - val_loss: 0.0405 - val_accuracy: 0.9967\n",
            "Epoch 274/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2128 - accuracy: 0.9324\n",
            "Epoch 274: val_loss did not improve from 0.03195\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2143 - accuracy: 0.9316 - val_loss: 0.0546 - val_accuracy: 0.9867\n",
            "Epoch 275/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.2005 - accuracy: 0.9325\n",
            "Epoch 275: val_loss improved from 0.03195 to 0.03065, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2002 - accuracy: 0.9311 - val_loss: 0.0306 - val_accuracy: 0.9950\n",
            "Epoch 276/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2291 - accuracy: 0.9200\n",
            "Epoch 276: val_loss did not improve from 0.03065\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2350 - accuracy: 0.9179 - val_loss: 0.0310 - val_accuracy: 0.9983\n",
            "Epoch 277/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2087 - accuracy: 0.9304\n",
            "Epoch 277: val_loss did not improve from 0.03065\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2107 - accuracy: 0.9307 - val_loss: 0.0340 - val_accuracy: 0.9983\n",
            "Epoch 278/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2240 - accuracy: 0.9266\n",
            "Epoch 278: val_loss did not improve from 0.03065\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2330 - accuracy: 0.9233 - val_loss: 0.0366 - val_accuracy: 0.9967\n",
            "Epoch 279/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.2072 - accuracy: 0.9292\n",
            "Epoch 279: val_loss did not improve from 0.03065\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2025 - accuracy: 0.9291 - val_loss: 0.0372 - val_accuracy: 0.9917\n",
            "Epoch 280/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.1929 - accuracy: 0.9366\n",
            "Epoch 280: val_loss did not improve from 0.03065\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2025 - accuracy: 0.9345 - val_loss: 0.0381 - val_accuracy: 0.9900\n",
            "Epoch 281/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2143 - accuracy: 0.9271\n",
            "Epoch 281: val_loss did not improve from 0.03065\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2117 - accuracy: 0.9282 - val_loss: 0.0360 - val_accuracy: 0.9917\n",
            "Epoch 282/1000\n",
            "29/38 [=====================>........] - ETA: 0s - loss: 0.2152 - accuracy: 0.9213\n",
            "Epoch 282: val_loss did not improve from 0.03065\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2090 - accuracy: 0.9245 - val_loss: 0.0394 - val_accuracy: 0.9950\n",
            "Epoch 283/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2025 - accuracy: 0.9280\n",
            "Epoch 283: val_loss did not improve from 0.03065\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2038 - accuracy: 0.9278 - val_loss: 0.0348 - val_accuracy: 0.9934\n",
            "Epoch 284/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2013 - accuracy: 0.9313\n",
            "Epoch 284: val_loss did not improve from 0.03065\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1985 - accuracy: 0.9316 - val_loss: 0.0383 - val_accuracy: 0.9967\n",
            "Epoch 285/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2110 - accuracy: 0.9288\n",
            "Epoch 285: val_loss improved from 0.03065 to 0.02807, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2092 - accuracy: 0.9287 - val_loss: 0.0281 - val_accuracy: 0.9983\n",
            "Epoch 286/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1937 - accuracy: 0.9321\n",
            "Epoch 286: val_loss did not improve from 0.02807\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1979 - accuracy: 0.9320 - val_loss: 0.0321 - val_accuracy: 0.9950\n",
            "Epoch 287/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.2072 - accuracy: 0.9318\n",
            "Epoch 287: val_loss did not improve from 0.02807\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2063 - accuracy: 0.9320 - val_loss: 0.0414 - val_accuracy: 0.9917\n",
            "Epoch 288/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2123 - accuracy: 0.9340\n",
            "Epoch 288: val_loss did not improve from 0.02807\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2103 - accuracy: 0.9332 - val_loss: 0.0366 - val_accuracy: 0.9967\n",
            "Epoch 289/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2095 - accuracy: 0.9263\n",
            "Epoch 289: val_loss did not improve from 0.02807\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2061 - accuracy: 0.9274 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
            "Epoch 290/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 0.2013 - accuracy: 0.9342\n",
            "Epoch 290: val_loss did not improve from 0.02807\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1945 - accuracy: 0.9370 - val_loss: 0.0324 - val_accuracy: 0.9967\n",
            "Epoch 291/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1854 - accuracy: 0.9402\n",
            "Epoch 291: val_loss did not improve from 0.02807\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1911 - accuracy: 0.9386 - val_loss: 0.0305 - val_accuracy: 0.9983\n",
            "Epoch 292/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1829 - accuracy: 0.9384\n",
            "Epoch 292: val_loss did not improve from 0.02807\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1839 - accuracy: 0.9374 - val_loss: 0.0292 - val_accuracy: 0.9967\n",
            "Epoch 293/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2012 - accuracy: 0.9317\n",
            "Epoch 293: val_loss did not improve from 0.02807\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2033 - accuracy: 0.9299 - val_loss: 0.0308 - val_accuracy: 0.9967\n",
            "Epoch 294/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2107 - accuracy: 0.9324\n",
            "Epoch 294: val_loss did not improve from 0.02807\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2052 - accuracy: 0.9324 - val_loss: 0.0303 - val_accuracy: 0.9967\n",
            "Epoch 295/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2022 - accuracy: 0.9336\n",
            "Epoch 295: val_loss did not improve from 0.02807\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1978 - accuracy: 0.9353 - val_loss: 0.0330 - val_accuracy: 0.9950\n",
            "Epoch 296/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2097 - accuracy: 0.9345\n",
            "Epoch 296: val_loss did not improve from 0.02807\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2117 - accuracy: 0.9336 - val_loss: 0.0302 - val_accuracy: 0.9967\n",
            "Epoch 297/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.1808 - accuracy: 0.9414\n",
            "Epoch 297: val_loss did not improve from 0.02807\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1993 - accuracy: 0.9374 - val_loss: 0.0337 - val_accuracy: 0.9967\n",
            "Epoch 298/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1942 - accuracy: 0.9336\n",
            "Epoch 298: val_loss did not improve from 0.02807\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1942 - accuracy: 0.9336 - val_loss: 0.0371 - val_accuracy: 0.9950\n",
            "Epoch 299/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2094 - accuracy: 0.9349\n",
            "Epoch 299: val_loss did not improve from 0.02807\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2066 - accuracy: 0.9357 - val_loss: 0.0353 - val_accuracy: 0.9967\n",
            "Epoch 300/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.2139 - accuracy: 0.9254\n",
            "Epoch 300: val_loss did not improve from 0.02807\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2111 - accuracy: 0.9270 - val_loss: 0.0365 - val_accuracy: 0.9967\n",
            "Epoch 301/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 0.1980 - accuracy: 0.9414\n",
            "Epoch 301: val_loss did not improve from 0.02807\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1941 - accuracy: 0.9386 - val_loss: 0.0370 - val_accuracy: 0.9934\n",
            "Epoch 302/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.1785 - accuracy: 0.9399\n",
            "Epoch 302: val_loss did not improve from 0.02807\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1790 - accuracy: 0.9403 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
            "Epoch 303/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1995 - accuracy: 0.9370\n",
            "Epoch 303: val_loss did not improve from 0.02807\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1999 - accuracy: 0.9370 - val_loss: 0.0301 - val_accuracy: 0.9950\n",
            "Epoch 304/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.1889 - accuracy: 0.9360\n",
            "Epoch 304: val_loss did not improve from 0.02807\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1865 - accuracy: 0.9357 - val_loss: 0.0314 - val_accuracy: 0.9967\n",
            "Epoch 305/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.1838 - accuracy: 0.9328\n",
            "Epoch 305: val_loss improved from 0.02807 to 0.02592, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1824 - accuracy: 0.9316 - val_loss: 0.0259 - val_accuracy: 0.9967\n",
            "Epoch 306/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1839 - accuracy: 0.9337\n",
            "Epoch 306: val_loss did not improve from 0.02592\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1831 - accuracy: 0.9341 - val_loss: 0.0320 - val_accuracy: 0.9967\n",
            "Epoch 307/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1621 - accuracy: 0.9466\n",
            "Epoch 307: val_loss did not improve from 0.02592\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1611 - accuracy: 0.9473 - val_loss: 0.0277 - val_accuracy: 0.9967\n",
            "Epoch 308/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1725 - accuracy: 0.9375\n",
            "Epoch 308: val_loss did not improve from 0.02592\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1802 - accuracy: 0.9361 - val_loss: 0.0312 - val_accuracy: 0.9983\n",
            "Epoch 309/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1680 - accuracy: 0.9458\n",
            "Epoch 309: val_loss did not improve from 0.02592\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1751 - accuracy: 0.9428 - val_loss: 0.0276 - val_accuracy: 0.9967\n",
            "Epoch 310/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.1764 - accuracy: 0.9408\n",
            "Epoch 310: val_loss did not improve from 0.02592\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1794 - accuracy: 0.9386 - val_loss: 0.0316 - val_accuracy: 0.9950\n",
            "Epoch 311/1000\n",
            "23/38 [=================>............] - ETA: 0s - loss: 0.1716 - accuracy: 0.9429\n",
            "Epoch 311: val_loss did not improve from 0.02592\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1752 - accuracy: 0.9436 - val_loss: 0.0351 - val_accuracy: 0.9917\n",
            "Epoch 312/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.1793 - accuracy: 0.9406\n",
            "Epoch 312: val_loss improved from 0.02592 to 0.02486, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.1754 - accuracy: 0.9423 - val_loss: 0.0249 - val_accuracy: 0.9967\n",
            "Epoch 313/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1780 - accuracy: 0.9357\n",
            "Epoch 313: val_loss did not improve from 0.02486\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1754 - accuracy: 0.9374 - val_loss: 0.0284 - val_accuracy: 0.9967\n",
            "Epoch 314/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1763 - accuracy: 0.9406\n",
            "Epoch 314: val_loss did not improve from 0.02486\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1794 - accuracy: 0.9399 - val_loss: 0.0305 - val_accuracy: 0.9967\n",
            "Epoch 315/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1852 - accuracy: 0.9386\n",
            "Epoch 315: val_loss improved from 0.02486 to 0.02439, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1852 - accuracy: 0.9386 - val_loss: 0.0244 - val_accuracy: 0.9983\n",
            "Epoch 316/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.1928 - accuracy: 0.9271\n",
            "Epoch 316: val_loss did not improve from 0.02439\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1946 - accuracy: 0.9278 - val_loss: 0.0338 - val_accuracy: 0.9950\n",
            "Epoch 317/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1780 - accuracy: 0.9393\n",
            "Epoch 317: val_loss did not improve from 0.02439\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1807 - accuracy: 0.9390 - val_loss: 0.0316 - val_accuracy: 0.9967\n",
            "Epoch 318/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1986 - accuracy: 0.9321\n",
            "Epoch 318: val_loss did not improve from 0.02439\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1949 - accuracy: 0.9328 - val_loss: 0.0360 - val_accuracy: 0.9934\n",
            "Epoch 319/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1675 - accuracy: 0.9453\n",
            "Epoch 319: val_loss did not improve from 0.02439\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1685 - accuracy: 0.9444 - val_loss: 0.0353 - val_accuracy: 0.9917\n",
            "Epoch 320/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.2060 - accuracy: 0.9324\n",
            "Epoch 320: val_loss did not improve from 0.02439\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.2040 - accuracy: 0.9336 - val_loss: 0.0277 - val_accuracy: 0.9983\n",
            "Epoch 321/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1722 - accuracy: 0.9451\n",
            "Epoch 321: val_loss improved from 0.02439 to 0.02370, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1705 - accuracy: 0.9453 - val_loss: 0.0237 - val_accuracy: 0.9967\n",
            "Epoch 322/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.1994 - accuracy: 0.9299\n",
            "Epoch 322: val_loss did not improve from 0.02370\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1947 - accuracy: 0.9299 - val_loss: 0.0280 - val_accuracy: 0.9967\n",
            "Epoch 323/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1863 - accuracy: 0.9340\n",
            "Epoch 323: val_loss did not improve from 0.02370\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1849 - accuracy: 0.9341 - val_loss: 0.0304 - val_accuracy: 0.9934\n",
            "Epoch 324/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1770 - accuracy: 0.9401\n",
            "Epoch 324: val_loss did not improve from 0.02370\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1745 - accuracy: 0.9403 - val_loss: 0.0239 - val_accuracy: 0.9967\n",
            "Epoch 325/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2000 - accuracy: 0.9293\n",
            "Epoch 325: val_loss did not improve from 0.02370\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2035 - accuracy: 0.9274 - val_loss: 0.0288 - val_accuracy: 0.9967\n",
            "Epoch 326/1000\n",
            "29/38 [=====================>........] - ETA: 0s - loss: 0.1728 - accuracy: 0.9429\n",
            "Epoch 326: val_loss did not improve from 0.02370\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1775 - accuracy: 0.9386 - val_loss: 0.0283 - val_accuracy: 0.9967\n",
            "Epoch 327/1000\n",
            "19/38 [==============>...............] - ETA: 0s - loss: 0.1455 - accuracy: 0.9539\n",
            "Epoch 327: val_loss did not improve from 0.02370\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1846 - accuracy: 0.9419 - val_loss: 0.0286 - val_accuracy: 0.9983\n",
            "Epoch 328/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1994 - accuracy: 0.9320\n",
            "Epoch 328: val_loss did not improve from 0.02370\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1994 - accuracy: 0.9320 - val_loss: 0.0368 - val_accuracy: 0.9934\n",
            "Epoch 329/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.1719 - accuracy: 0.9453\n",
            "Epoch 329: val_loss did not improve from 0.02370\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1720 - accuracy: 0.9453 - val_loss: 0.0329 - val_accuracy: 0.9884\n",
            "Epoch 330/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.1793 - accuracy: 0.9394\n",
            "Epoch 330: val_loss did not improve from 0.02370\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1739 - accuracy: 0.9415 - val_loss: 0.0363 - val_accuracy: 0.9950\n",
            "Epoch 331/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1910 - accuracy: 0.9277\n",
            "Epoch 331: val_loss did not improve from 0.02370\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1937 - accuracy: 0.9278 - val_loss: 0.0285 - val_accuracy: 0.9967\n",
            "Epoch 332/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.1671 - accuracy: 0.9451\n",
            "Epoch 332: val_loss did not improve from 0.02370\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1646 - accuracy: 0.9457 - val_loss: 0.0286 - val_accuracy: 0.9967\n",
            "Epoch 333/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1928 - accuracy: 0.9329\n",
            "Epoch 333: val_loss did not improve from 0.02370\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1907 - accuracy: 0.9341 - val_loss: 0.0260 - val_accuracy: 0.9967\n",
            "Epoch 334/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1842 - accuracy: 0.9374\n",
            "Epoch 334: val_loss did not improve from 0.02370\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1842 - accuracy: 0.9374 - val_loss: 0.0261 - val_accuracy: 0.9967\n",
            "Epoch 335/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1859 - accuracy: 0.9444\n",
            "Epoch 335: val_loss did not improve from 0.02370\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1873 - accuracy: 0.9448 - val_loss: 0.0302 - val_accuracy: 0.9950\n",
            "Epoch 336/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1869 - accuracy: 0.9384\n",
            "Epoch 336: val_loss did not improve from 0.02370\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1818 - accuracy: 0.9394 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
            "Epoch 337/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1851 - accuracy: 0.9436\n",
            "Epoch 337: val_loss did not improve from 0.02370\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1911 - accuracy: 0.9419 - val_loss: 0.0286 - val_accuracy: 0.9983\n",
            "Epoch 338/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1717 - accuracy: 0.9462\n",
            "Epoch 338: val_loss did not improve from 0.02370\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1729 - accuracy: 0.9444 - val_loss: 0.0295 - val_accuracy: 0.9917\n",
            "Epoch 339/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1854 - accuracy: 0.9384\n",
            "Epoch 339: val_loss did not improve from 0.02370\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1867 - accuracy: 0.9386 - val_loss: 0.0278 - val_accuracy: 0.9983\n",
            "Epoch 340/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.1893 - accuracy: 0.9360\n",
            "Epoch 340: val_loss did not improve from 0.02370\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1875 - accuracy: 0.9411 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
            "Epoch 341/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.1904 - accuracy: 0.9333\n",
            "Epoch 341: val_loss did not improve from 0.02370\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1832 - accuracy: 0.9378 - val_loss: 0.0256 - val_accuracy: 0.9967\n",
            "Epoch 342/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.1900 - accuracy: 0.9384\n",
            "Epoch 342: val_loss improved from 0.02370 to 0.02364, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.1905 - accuracy: 0.9378 - val_loss: 0.0236 - val_accuracy: 0.9983\n",
            "Epoch 343/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1717 - accuracy: 0.9405\n",
            "Epoch 343: val_loss did not improve from 0.02364\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1696 - accuracy: 0.9415 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
            "Epoch 344/1000\n",
            "23/38 [=================>............] - ETA: 0s - loss: 0.1823 - accuracy: 0.9457\n",
            "Epoch 344: val_loss did not improve from 0.02364\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1729 - accuracy: 0.9486 - val_loss: 0.0249 - val_accuracy: 0.9967\n",
            "Epoch 345/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1730 - accuracy: 0.9453\n",
            "Epoch 345: val_loss did not improve from 0.02364\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1735 - accuracy: 0.9453 - val_loss: 0.0361 - val_accuracy: 0.9950\n",
            "Epoch 346/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1830 - accuracy: 0.9462\n",
            "Epoch 346: val_loss did not improve from 0.02364\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1810 - accuracy: 0.9469 - val_loss: 0.0257 - val_accuracy: 0.9950\n",
            "Epoch 347/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1735 - accuracy: 0.9433\n",
            "Epoch 347: val_loss did not improve from 0.02364\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1749 - accuracy: 0.9436 - val_loss: 0.0287 - val_accuracy: 0.9983\n",
            "Epoch 348/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1496 - accuracy: 0.9426\n",
            "Epoch 348: val_loss improved from 0.02364 to 0.02193, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1500 - accuracy: 0.9423 - val_loss: 0.0219 - val_accuracy: 0.9983\n",
            "Epoch 349/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1931 - accuracy: 0.9308\n",
            "Epoch 349: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1871 - accuracy: 0.9324 - val_loss: 0.0253 - val_accuracy: 0.9983\n",
            "Epoch 350/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 0.1879 - accuracy: 0.9369\n",
            "Epoch 350: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1895 - accuracy: 0.9365 - val_loss: 0.0328 - val_accuracy: 0.9967\n",
            "Epoch 351/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1723 - accuracy: 0.9388\n",
            "Epoch 351: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1705 - accuracy: 0.9403 - val_loss: 0.0316 - val_accuracy: 0.9934\n",
            "Epoch 352/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1760 - accuracy: 0.9421\n",
            "Epoch 352: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1708 - accuracy: 0.9436 - val_loss: 0.0266 - val_accuracy: 0.9983\n",
            "Epoch 353/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1771 - accuracy: 0.9415\n",
            "Epoch 353: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1776 - accuracy: 0.9411 - val_loss: 0.0270 - val_accuracy: 0.9983\n",
            "Epoch 354/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1818 - accuracy: 0.9418\n",
            "Epoch 354: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1825 - accuracy: 0.9407 - val_loss: 0.0350 - val_accuracy: 0.9967\n",
            "Epoch 355/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1592 - accuracy: 0.9457\n",
            "Epoch 355: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1566 - accuracy: 0.9469 - val_loss: 0.0282 - val_accuracy: 0.9967\n",
            "Epoch 356/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.1802 - accuracy: 0.9391\n",
            "Epoch 356: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1872 - accuracy: 0.9374 - val_loss: 0.0349 - val_accuracy: 0.9967\n",
            "Epoch 357/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.1559 - accuracy: 0.9479\n",
            "Epoch 357: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1657 - accuracy: 0.9453 - val_loss: 0.0222 - val_accuracy: 0.9967\n",
            "Epoch 358/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.1743 - accuracy: 0.9432\n",
            "Epoch 358: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1767 - accuracy: 0.9444 - val_loss: 0.0337 - val_accuracy: 0.9950\n",
            "Epoch 359/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.1634 - accuracy: 0.9389\n",
            "Epoch 359: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1669 - accuracy: 0.9361 - val_loss: 0.0323 - val_accuracy: 0.9967\n",
            "Epoch 360/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1807 - accuracy: 0.9405\n",
            "Epoch 360: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1811 - accuracy: 0.9399 - val_loss: 0.0291 - val_accuracy: 0.9967\n",
            "Epoch 361/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1936 - accuracy: 0.9370\n",
            "Epoch 361: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1914 - accuracy: 0.9386 - val_loss: 0.0285 - val_accuracy: 0.9967\n",
            "Epoch 362/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1590 - accuracy: 0.9460\n",
            "Epoch 362: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1604 - accuracy: 0.9457 - val_loss: 0.0304 - val_accuracy: 0.9884\n",
            "Epoch 363/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1694 - accuracy: 0.9420\n",
            "Epoch 363: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1684 - accuracy: 0.9423 - val_loss: 0.0252 - val_accuracy: 0.9983\n",
            "Epoch 364/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1686 - accuracy: 0.9430\n",
            "Epoch 364: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1707 - accuracy: 0.9428 - val_loss: 0.0258 - val_accuracy: 0.9967\n",
            "Epoch 365/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1760 - accuracy: 0.9436\n",
            "Epoch 365: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1717 - accuracy: 0.9453 - val_loss: 0.0291 - val_accuracy: 0.9950\n",
            "Epoch 366/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1819 - accuracy: 0.9411\n",
            "Epoch 366: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1811 - accuracy: 0.9411 - val_loss: 0.0279 - val_accuracy: 0.9967\n",
            "Epoch 367/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1584 - accuracy: 0.9469\n",
            "Epoch 367: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1587 - accuracy: 0.9461 - val_loss: 0.0255 - val_accuracy: 0.9967\n",
            "Epoch 368/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1736 - accuracy: 0.9398\n",
            "Epoch 368: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1729 - accuracy: 0.9394 - val_loss: 0.0301 - val_accuracy: 0.9917\n",
            "Epoch 369/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1673 - accuracy: 0.9468\n",
            "Epoch 369: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1678 - accuracy: 0.9465 - val_loss: 0.0225 - val_accuracy: 0.9950\n",
            "Epoch 370/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1808 - accuracy: 0.9415\n",
            "Epoch 370: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1808 - accuracy: 0.9415 - val_loss: 0.0259 - val_accuracy: 0.9950\n",
            "Epoch 371/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1782 - accuracy: 0.9436\n",
            "Epoch 371: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1755 - accuracy: 0.9440 - val_loss: 0.0387 - val_accuracy: 0.9917\n",
            "Epoch 372/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1763 - accuracy: 0.9366\n",
            "Epoch 372: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1711 - accuracy: 0.9386 - val_loss: 0.0282 - val_accuracy: 0.9950\n",
            "Epoch 373/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1814 - accuracy: 0.9453\n",
            "Epoch 373: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1785 - accuracy: 0.9465 - val_loss: 0.0295 - val_accuracy: 0.9983\n",
            "Epoch 374/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.1721 - accuracy: 0.9437\n",
            "Epoch 374: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1794 - accuracy: 0.9419 - val_loss: 0.0267 - val_accuracy: 0.9983\n",
            "Epoch 375/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1663 - accuracy: 0.9402\n",
            "Epoch 375: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1653 - accuracy: 0.9399 - val_loss: 0.0266 - val_accuracy: 0.9967\n",
            "Epoch 376/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.1620 - accuracy: 0.9443\n",
            "Epoch 376: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1608 - accuracy: 0.9444 - val_loss: 0.0303 - val_accuracy: 0.9967\n",
            "Epoch 377/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1713 - accuracy: 0.9421\n",
            "Epoch 377: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1743 - accuracy: 0.9407 - val_loss: 0.0247 - val_accuracy: 0.9983\n",
            "Epoch 378/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1459 - accuracy: 0.9491\n",
            "Epoch 378: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1471 - accuracy: 0.9482 - val_loss: 0.0278 - val_accuracy: 0.9967\n",
            "Epoch 379/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1384 - accuracy: 0.9550\n",
            "Epoch 379: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1396 - accuracy: 0.9527 - val_loss: 0.0268 - val_accuracy: 0.9950\n",
            "Epoch 380/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1717 - accuracy: 0.9419\n",
            "Epoch 380: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1717 - accuracy: 0.9419 - val_loss: 0.0321 - val_accuracy: 0.9934\n",
            "Epoch 381/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1587 - accuracy: 0.9439\n",
            "Epoch 381: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1651 - accuracy: 0.9415 - val_loss: 0.0267 - val_accuracy: 0.9967\n",
            "Epoch 382/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1739 - accuracy: 0.9407\n",
            "Epoch 382: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1739 - accuracy: 0.9407 - val_loss: 0.0332 - val_accuracy: 0.9934\n",
            "Epoch 383/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1790 - accuracy: 0.9345\n",
            "Epoch 383: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1781 - accuracy: 0.9349 - val_loss: 0.0315 - val_accuracy: 0.9950\n",
            "Epoch 384/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1827 - accuracy: 0.9388\n",
            "Epoch 384: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1789 - accuracy: 0.9399 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
            "Epoch 385/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1581 - accuracy: 0.9504\n",
            "Epoch 385: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1549 - accuracy: 0.9506 - val_loss: 0.0283 - val_accuracy: 0.9950\n",
            "Epoch 386/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1859 - accuracy: 0.9424\n",
            "Epoch 386: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1865 - accuracy: 0.9411 - val_loss: 0.0244 - val_accuracy: 0.9967\n",
            "Epoch 387/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1636 - accuracy: 0.9429\n",
            "Epoch 387: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1642 - accuracy: 0.9423 - val_loss: 0.0229 - val_accuracy: 0.9983\n",
            "Epoch 388/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1704 - accuracy: 0.9418\n",
            "Epoch 388: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1726 - accuracy: 0.9419 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
            "Epoch 389/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1483 - accuracy: 0.9517\n",
            "Epoch 389: val_loss did not improve from 0.02193\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1497 - accuracy: 0.9502 - val_loss: 0.0259 - val_accuracy: 0.9967\n",
            "Epoch 390/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.1485 - accuracy: 0.9471\n",
            "Epoch 390: val_loss improved from 0.02193 to 0.01639, saving model to ./model/Hand_Point\\HandPoint.hdf5\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1522 - accuracy: 0.9477 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
            "Epoch 391/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.1577 - accuracy: 0.9398\n",
            "Epoch 391: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1655 - accuracy: 0.9444 - val_loss: 0.0205 - val_accuracy: 0.9983\n",
            "Epoch 392/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.1490 - accuracy: 0.9493\n",
            "Epoch 392: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1537 - accuracy: 0.9473 - val_loss: 0.0306 - val_accuracy: 0.9934\n",
            "Epoch 393/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1658 - accuracy: 0.9485\n",
            "Epoch 393: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1629 - accuracy: 0.9490 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
            "Epoch 394/1000\n",
            "25/38 [==================>...........] - ETA: 0s - loss: 0.1447 - accuracy: 0.9506\n",
            "Epoch 394: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1564 - accuracy: 0.9482 - val_loss: 0.0200 - val_accuracy: 0.9967\n",
            "Epoch 395/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1622 - accuracy: 0.9429\n",
            "Epoch 395: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1574 - accuracy: 0.9448 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
            "Epoch 396/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1692 - accuracy: 0.9392\n",
            "Epoch 396: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1663 - accuracy: 0.9399 - val_loss: 0.0235 - val_accuracy: 0.9983\n",
            "Epoch 397/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1375 - accuracy: 0.9527\n",
            "Epoch 397: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1356 - accuracy: 0.9535 - val_loss: 0.0207 - val_accuracy: 0.9967\n",
            "Epoch 398/1000\n",
            "23/38 [=================>............] - ETA: 0s - loss: 0.1683 - accuracy: 0.9457\n",
            "Epoch 398: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1767 - accuracy: 0.9444 - val_loss: 0.0266 - val_accuracy: 0.9950\n",
            "Epoch 399/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1682 - accuracy: 0.9443\n",
            "Epoch 399: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1678 - accuracy: 0.9440 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
            "Epoch 400/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1527 - accuracy: 0.9476\n",
            "Epoch 400: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1518 - accuracy: 0.9477 - val_loss: 0.0288 - val_accuracy: 0.9967\n",
            "Epoch 401/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.1518 - accuracy: 0.9489\n",
            "Epoch 401: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1562 - accuracy: 0.9465 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
            "Epoch 402/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1554 - accuracy: 0.9527\n",
            "Epoch 402: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1548 - accuracy: 0.9515 - val_loss: 0.0258 - val_accuracy: 0.9967\n",
            "Epoch 403/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.1742 - accuracy: 0.9420\n",
            "Epoch 403: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1684 - accuracy: 0.9407 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
            "Epoch 404/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1610 - accuracy: 0.9432\n",
            "Epoch 404: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1610 - accuracy: 0.9432 - val_loss: 0.0234 - val_accuracy: 0.9983\n",
            "Epoch 405/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.1684 - accuracy: 0.9432\n",
            "Epoch 405: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1683 - accuracy: 0.9444 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
            "Epoch 406/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1688 - accuracy: 0.9430\n",
            "Epoch 406: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1675 - accuracy: 0.9436 - val_loss: 0.0221 - val_accuracy: 0.9983\n",
            "Epoch 407/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.1629 - accuracy: 0.9506\n",
            "Epoch 407: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1677 - accuracy: 0.9490 - val_loss: 0.0210 - val_accuracy: 0.9983\n",
            "Epoch 408/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1724 - accuracy: 0.9451\n",
            "Epoch 408: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1714 - accuracy: 0.9457 - val_loss: 0.0277 - val_accuracy: 0.9983\n",
            "Epoch 409/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1568 - accuracy: 0.9472\n",
            "Epoch 409: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1542 - accuracy: 0.9473 - val_loss: 0.0198 - val_accuracy: 0.9983\n",
            "Epoch 410/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1474 - accuracy: 0.9481\n",
            "Epoch 410: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1517 - accuracy: 0.9461 - val_loss: 0.0199 - val_accuracy: 0.9967\n",
            "Epoch 411/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.1492 - accuracy: 0.9427\n",
            "Epoch 411: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1558 - accuracy: 0.9432 - val_loss: 0.0240 - val_accuracy: 0.9983\n",
            "Epoch 412/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 0.1493 - accuracy: 0.9526\n",
            "Epoch 412: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1498 - accuracy: 0.9531 - val_loss: 0.0225 - val_accuracy: 0.9950\n",
            "Epoch 413/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.1434 - accuracy: 0.9501\n",
            "Epoch 413: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1502 - accuracy: 0.9465 - val_loss: 0.0339 - val_accuracy: 0.9917\n",
            "Epoch 414/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1522 - accuracy: 0.9488\n",
            "Epoch 414: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1526 - accuracy: 0.9486 - val_loss: 0.0289 - val_accuracy: 0.9967\n",
            "Epoch 415/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.1565 - accuracy: 0.9484\n",
            "Epoch 415: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1579 - accuracy: 0.9490 - val_loss: 0.0305 - val_accuracy: 0.9934\n",
            "Epoch 416/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.1756 - accuracy: 0.9380\n",
            "Epoch 416: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1671 - accuracy: 0.9423 - val_loss: 0.0422 - val_accuracy: 0.9867\n",
            "Epoch 417/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1732 - accuracy: 0.9379\n",
            "Epoch 417: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1712 - accuracy: 0.9399 - val_loss: 0.0268 - val_accuracy: 0.9967\n",
            "Epoch 418/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.1427 - accuracy: 0.9561\n",
            "Epoch 418: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1384 - accuracy: 0.9577 - val_loss: 0.0215 - val_accuracy: 0.9967\n",
            "Epoch 419/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1461 - accuracy: 0.9531\n",
            "Epoch 419: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1546 - accuracy: 0.9502 - val_loss: 0.0281 - val_accuracy: 0.9900\n",
            "Epoch 420/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.1710 - accuracy: 0.9422\n",
            "Epoch 420: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1616 - accuracy: 0.9428 - val_loss: 0.0238 - val_accuracy: 0.9967\n",
            "Epoch 421/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.1615 - accuracy: 0.9484\n",
            "Epoch 421: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1572 - accuracy: 0.9494 - val_loss: 0.0353 - val_accuracy: 0.9967\n",
            "Epoch 422/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1657 - accuracy: 0.9402\n",
            "Epoch 422: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1652 - accuracy: 0.9403 - val_loss: 0.0231 - val_accuracy: 0.9967\n",
            "Epoch 423/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1524 - accuracy: 0.9527\n",
            "Epoch 423: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1487 - accuracy: 0.9535 - val_loss: 0.0258 - val_accuracy: 0.9967\n",
            "Epoch 424/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.1698 - accuracy: 0.9424\n",
            "Epoch 424: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1687 - accuracy: 0.9428 - val_loss: 0.0262 - val_accuracy: 0.9900\n",
            "Epoch 425/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.1318 - accuracy: 0.9555\n",
            "Epoch 425: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1500 - accuracy: 0.9502 - val_loss: 0.0218 - val_accuracy: 0.9967\n",
            "Epoch 426/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1624 - accuracy: 0.9446\n",
            "Epoch 426: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1643 - accuracy: 0.9432 - val_loss: 0.0288 - val_accuracy: 0.9967\n",
            "Epoch 427/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.1398 - accuracy: 0.9484\n",
            "Epoch 427: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1487 - accuracy: 0.9461 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
            "Epoch 428/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1601 - accuracy: 0.9500\n",
            "Epoch 428: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1621 - accuracy: 0.9490 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
            "Epoch 429/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1568 - accuracy: 0.9426\n",
            "Epoch 429: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1575 - accuracy: 0.9415 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
            "Epoch 430/1000\n",
            "24/38 [=================>............] - ETA: 0s - loss: 0.1591 - accuracy: 0.9473\n",
            "Epoch 430: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1664 - accuracy: 0.9465 - val_loss: 0.0283 - val_accuracy: 0.9967\n",
            "Epoch 431/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.1584 - accuracy: 0.9433\n",
            "Epoch 431: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1577 - accuracy: 0.9436 - val_loss: 0.0224 - val_accuracy: 0.9967\n",
            "Epoch 432/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1440 - accuracy: 0.9513\n",
            "Epoch 432: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1414 - accuracy: 0.9523 - val_loss: 0.0244 - val_accuracy: 0.9950\n",
            "Epoch 433/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1726 - accuracy: 0.9448\n",
            "Epoch 433: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1726 - accuracy: 0.9448 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
            "Epoch 434/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.1524 - accuracy: 0.9531\n",
            "Epoch 434: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1457 - accuracy: 0.9544 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
            "Epoch 435/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.1408 - accuracy: 0.9536\n",
            "Epoch 435: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1397 - accuracy: 0.9535 - val_loss: 0.0231 - val_accuracy: 0.9967\n",
            "Epoch 436/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1459 - accuracy: 0.9514\n",
            "Epoch 436: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1488 - accuracy: 0.9502 - val_loss: 0.0172 - val_accuracy: 0.9967\n",
            "Epoch 437/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1334 - accuracy: 0.9552\n",
            "Epoch 437: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1334 - accuracy: 0.9552 - val_loss: 0.0201 - val_accuracy: 0.9950\n",
            "Epoch 438/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1484 - accuracy: 0.9497\n",
            "Epoch 438: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1487 - accuracy: 0.9494 - val_loss: 0.0293 - val_accuracy: 0.9967\n",
            "Epoch 439/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.1311 - accuracy: 0.9623\n",
            "Epoch 439: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.1355 - accuracy: 0.9623 - val_loss: 0.0243 - val_accuracy: 0.9950\n",
            "Epoch 440/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.1667 - accuracy: 0.9507\n",
            "Epoch 440: val_loss did not improve from 0.01639\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.1648 - accuracy: 0.9498 - val_loss: 0.0286 - val_accuracy: 0.9967\n",
            "Epoch 440: early stopping\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=1000,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[cp_callback, es_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA2KklEQVR4nO3deXhV1b3/8ff3DDmZEzIwhABhlhkUERxRqyJarXWiDtVee9Fbe2t/tVZtrd62t9rh1um2tnVqrfZarah1wApanGUIiMxDmEzCkJB5zhnW74+1ExIIECAnh2R/X8+TJ+fsvc/e62xxf7LW2mttMcaglFLKvTyxLoBSSqnY0iBQSimX0yBQSimX0yBQSimX0yBQSimX0yBQSimX0yBQqpNE5M8i8t+d3Ha7iHzpWPejVHfQIFBKKZfTIFBKKZfTIFC9itMkc4eIrBKROhF5SkT6ichbIlIjIu+ISJ82218iImtFpFJE3hORMW3WTRGRFc7nXgDi9zvWxSKy0vnsJyIy8SjL/O8iUiAi5SLymojkOMtFRB4SkRIRqRaR1SIy3lk3W0TWOWUrFpHvH9UJUwoNAtU7XQ6cB4wCvgy8BfwQyMb+m/8OgIiMAp4Hvuusmw+8LiJxIhIHvAo8C2QAf3f2i/PZKcDTwM1AJvBH4DURCRxJQUXkHOAB4CpgALAD+Juz+nzgTOd7pDnblDnrngJuNsakAOOBfx3JcZVqS4NA9Ub/a4zZY4wpBj4ElhhjPjPGNAKvAFOc7a4G3jTGLDTGBIH/ARKAU4HpgB942BgTNMa8BCxrc4y5wB+NMUuMMWFjzDNAk/O5I3Et8LQxZoUxpgm4G5ghInlAEEgBTgDEGLPeGLPL+VwQGCsiqcaYCmPMiiM8rlKtNAhUb7SnzeuGDt4nO69zsH+BA2CMiQCFwEBnXbFpPyvjjjavhwC3O81ClSJSCQxyPnck9i9DLfav/oHGmH8BvwV+B5SIyOMikupsejkwG9ghIu+LyIwjPK5SrTQIlJvtxF7QAdsmj72YFwO7gIHOshaD27wuBH5ujElv85NojHn+GMuQhG1qKgYwxjxqjDkJGIttIrrDWb7MGHMp0BfbhPXiER5XqVYaBMrNXgQuEpFzRcQP3I5t3vkE+BQIAd8REb+IfBWY1uazTwC3iMgpTqdukohcJCIpR1iG54FviMhkp3/hfmxT1nYROdnZvx+oAxqBiNOHca2IpDlNWtVA5BjOg3I5DQLlWsaYjcB1wP8Ce7Edy182xjQbY5qBrwI3AuXY/oSX23w2H/h3bNNNBVDgbHukZXgH+DEwD1sLGQ7McVanYgOnAtt8VAb82ll3PbBdRKqBW7B9DUodFdEH0yillLtpjUAppVxOg0AppVxOg0AppVxOg0AppVzOF+sCHKmsrCyTl5cX62IopVSPsnz58r3GmOyO1vW4IMjLyyM/Pz/WxVBKqR5FRHYcbJ02DSmllMtpECillMtpECillMv1uD6CjgSDQYqKimhsbIx1UaIuPj6e3Nxc/H5/rIuilOolekUQFBUVkZKSQl5eHu0ni+xdjDGUlZVRVFTE0KFDY10cpVQv0SuahhobG8nMzOzVIQAgImRmZrqi5qOU6j69IgiAXh8CLdzyPZVS3afXBMHhNATD7K5qIBTWaduVUqot1wRBcyhMSU0TwXDXT7tdWVnJY489dsSfmz17NpWVlV1eHqWUOhKuCQKv06QSjnRfEIRCoUN+bv78+aSnp3d5eZRS6kj0iruGOsPrcYIgCg/iueuuu9iyZQuTJ0/G7/cTHx9Pnz592LBhA5s2beIrX/kKhYWFNDY2cttttzF37lxg33QZtbW1XHjhhZx++ul88sknDBw4kH/84x8kJCR0eVmVUmp/vS4IfvL6WtbtrD5guTGG+uYwAb8Xn+fIOlzH5qRy35fHHXT9L37xC9asWcPKlSt57733uOiii1izZk3rLZ5PP/00GRkZNDQ0cPLJJ3P55ZeTmZnZbh+bN2/m+eef54knnuCqq65i3rx5XHfddUdUTqWUOhq9LggOymkaso/mjO6dN9OmTWt3n/+jjz7KK6+8AkBhYSGbN28+IAiGDh3K5MmTATjppJPYvn17VMuolFItel0QHOwvd2MMq4ur6JsST/+0+KiWISkpqfX1e++9xzvvvMOnn35KYmIiM2fO7HAcQCAQaH3t9XppaGiIahmVUqqFazqLpbGK8Z7tSLjrB2OlpKRQU1PT4bqqqir69OlDYmIiGzZsYPHixV1+fKWUOha9rkZwcIIHg4l0/TiCzMxMTjvtNMaPH09CQgL9+vVrXTdr1iz+8Ic/MGbMGEaPHs306dO7/PhKKXUsxEThLppomjp1qtn/wTTr169nzJgxh/5gUw2UFbDLl8uAvh0+pKfH6NT3VUqpNkRkuTFmakfrXNM0hDhf1ejIYqWUaitqQSAi8SKyVEQ+F5G1IvKTDrYJiMgLIlIgIktEJC9a5WkJAhMJR+0QSinVE0WzRtAEnGOMmQRMBmaJyP4N5DcBFcaYEcBDwC+jVhrx2l9aI1BKqXaiFgTGqnXe+p2f/TskLgWecV6/BJwr0Zpes6VpCA0CpZRqK6p9BCLiFZGVQAmw0BizZL9NBgKFAMaYEFAFZO63DSIyV0TyRSS/tLT06ArjsV9VTISe1kGulFLRFNUgMMaEjTGTgVxgmoiMP8r9PG6MmWqMmZqdfZR3/IgHA3iIoDmglFL7dMtdQ8aYSmARMGu/VcXAIAAR8QFpQFnUyoEHD4ZIFyfB0U5DDfDwww9TX1/fpeVRSqkjEc27hrJFJN15nQCcB2zYb7PXgBuc11cA/zJRbLcxokGglFL7i+bI4gHAMyLixQbOi8aYN0Tkp0C+MeY14CngWREpAMqBOVEsD4gXDxG6+pEEbaehPu+88+jbty8vvvgiTU1NXHbZZfzkJz+hrq6Oq666iqKiIsLhMD/+8Y/Zs2cPO3fu5OyzzyYrK4tFixZ1bcGUUqoTohYExphVwJQOlt/b5nUjcGWXHvitu2D36g5XeYL1JBsQf0LrbKSd0n8CXPiLg65uOw31ggULeOmll1i6dCnGGC655BI++OADSktLycnJ4c033wTsHERpaWk8+OCDLFq0iKysrCP6mkop1VXcM7LYIZio3jW0YMECFixYwJQpUzjxxBPZsGEDmzdvZsKECSxcuJA777yTDz/8kLS0tKiVQSmljkTvm3TuEH+5R/YW0NTURDBjFGkJ/qgc3hjD3Xffzc0333zAuhUrVjB//nzuuecezj33XO69994O9qCUUt3LXTWCls7iLu4kaDsN9QUXXMDTTz9Nba0dS1dcXExJSQk7d+4kMTGR6667jjvuuIMVK1Yc8FmllIqF3lcjOARp7Szu2iBoOw31hRdeyDXXXMOMGTMASE5O5rnnnqOgoIA77rgDj8eD3+/n97//PQBz585l1qxZ5OTkaGexUiom3DMNNWAqCwnXlVOeOpq+KdF9Slk06TTUSqkjpdNQt2htGop1QZRS6vjhrqYhjweRrh9QppRSPVmvqRF0romr5ZkEPbdK0NOa8pRSx79eEQTx8fGUlZUd/iLZ8nAa0zMfTmOMoaysjPj4ntu/oZQ6/vSKpqHc3FyKioo47BTVzbVQX06F11BTktA9heti8fHx5ObmxroYSqlepFcEgd/vZ+jQoYffcPVL8PZNfC/7CR689aroF0wppXqAXtE01Gn+RAAiQZ3tUymlWrgsCGxzULipIcYFUUqp44fLgsDWCERrBEop1cplQeDcbRPSGoFSSrVwWRDYGoEn1KD34yullMNlQWD7COJME02hnjuoTCmlupLLgsDWCBJopq4pFOPCKKXU8cFlQWBrBAk0Ud/cM0cXK6VUV3NXEPhsZ3GCNFPXrDUCpZQCtwWBCGFvAgFtGlJKqVbuCgIg4ksggSYamrWzWCmlIIpBICKDRGSRiKwTkbUiclsH28wUkSoRWen8RP1p7sYXTwLN1GvTkFJKAdGddC4E3G6MWSEiKcByEVlojFm333YfGmMujmI52vMnkCBNNAS1s1gppSCKNQJjzC5jzArndQ2wHhgYreN1mj+ReJpp1CBQSimgm/oIRCQPmAIs6WD1DBH5XETeEpFxB/n8XBHJF5H8wz5z4DA8cS19BBoESikF3RAEIpIMzAO+a4yp3m/1CmCIMWYS8L/Aqx3twxjzuDFmqjFmanZ29rGVJy6RBGmmIaidxUopBVEOAhHxY0Pgr8aYl/dfb4ypNsbUOq/nA34RyYpmmTxxtmlI+wiUUsqK5l1DAjwFrDfGPHiQbfo72yEi05zylEWrTADiTyRRtI9AKaVaRPOuodOA64HVIrLSWfZDYDCAMeYPwBXAf4hICGgA5phoTwvqj7dNQ9pHoJRSQBSDwBjzESCH2ea3wG+jVYYO+RNtZ7HWCJRSCnDhyGL8CbaPQGsESikFuDIIEgnQTGNzMNYlUUqp44ILg0AfYK+UUm25MAjsw2nC+gB7pZQCXBkEtkaABoFSSgGuDgJtGlJKKXBjEPg0CJRSqi33BYFTI/CEtGlIKaXAjUHgPLeYUFNsy6GUUscJFwZBHACeSJBgWGcgVUopFwaBrREECOo0E0ophRuDwBsAII4gjTrNhFJKuTAInKahgGiNQCmlwJVBoE1DSinVlvuCwGtrBHGEdAZSpZTCjUHg29dHoDUCpZRyYxA4ncUBgvq4SqWUwo1B4PFgPH7iJEhDs44jUEop9wUBYLxxto9AawRKKeXOIMAXb+8aag7FuiRKKRVzLg2COO0sVkophyuDQHwB4iSkfQRKKUUUg0BEBonIIhFZJyJrReS2DrYREXlURApEZJWInBit8rQ7ri+eBB1ZrJRSAPiiuO8QcLsxZoWIpADLRWShMWZdm20uBEY6P6cAv3d+R5c3jgRPSG8fVUopolgjMMbsMsascF7XAOuBgfttdinwF2MtBtJFZEC0ytTKFyBewjqyWCml6KY+AhHJA6YAS/ZbNRAobPO+iAPDAhGZKyL5IpJfWlp67AXyBrRpSCmlHFEPAhFJBuYB3zXGVB/NPowxjxtjphpjpmZnZx97oXwBAqLjCJRSCqIcBCLix4bAX40xL3ewSTEwqM37XGdZdPkCxIlOMaGUUhDdu4YEeApYb4x58CCbvQZ83bl7aDpQZYzZFa0ytfLGEdDZR5VSCojuXUOnAdcDq0VkpbPsh8BgAGPMH4D5wGygAKgHvhHF8uzjiyeOZuo1CJRSKnpBYIz5CJDDbGOAW6NVhoPyxeE3evuoUkqBS0cW4w3g1ykmlFIKcGsQ+AL4TLMGgVJKEd0+guOXBoFSSrVyZ43AG8BrwgRDISIRE+vSKKVUTLkzCNo8t7gxpLUCpZS7uT4IdCyBUsrt3BkE3jgAO6hM+wmUUi7nziDwxQMQEK0RKKWUS4OgTdOQ1giUUi7nziBwmobidL4hpZRyaRC0NA2hYwmUUsqlQaA1AqWUatGpIBCR20Qk1Zku+ikRWSEi50e7cFHjdfoIJEhNUyjGhVFKqdjqbI3g35yni50P9MFOL/2LqJUq2pzO4gBBahs1CJRS7tbZIGiZTno28KwxZi2HmWL6uNZ611CIGg0CpZTLdTYIlovIAmwQvC0iKUAkesWKMqdpKNkXpqYxGOPCKKVUbHV29tGbgMnAVmNMvYhk0F1PE4sGp7M4zR/WGoFSyvU6WyOYAWw0xlSKyHXAPUBV9IoVZc7toym+CDVNWiNQSrlbZ4Pg90C9iEwCbge2AH+JWqmizRlQluKLaI1AKeV6nQ2CkPN84UuB3xpjfgekRK9YUeZ0Fif5wlRrECilXK6zfQQ1InI39rbRM0TEA/ijV6woczqLU7zaWayUUp2tEVwNNGHHE+wGcoFfR61U0ebxgMdPoldvH1VKqU4FgXPx/yuQJiIXA43GmEP2EYjI0yJSIiJrDrJ+pohUichK5+feIy79sfAFSPBojUAppTo7xcRVwFLgSuAqYImIXHGYj/0ZmHWYbT40xkx2fn7ambJ0GV+ARE+IxmCE5lDPHRKhlFLHqrN9BD8CTjbGlACISDbwDvDSwT5gjPlARPKOuYTR4g2Q4LXNQhX1zfRLjY9xgZRSKjY620fgaQkBR9kRfPZQZojI5yLyloiMO9hGIjJXRPJFJL+0tLQLDoutEYhtFiqrbe6afSqlVA/U2RrBP0XkbeB55/3VwPxjPPYKYIgxplZEZgOvAiM72tAY8zjwOMDUqVPNMR7X8ieSIDYAyus0CJRS7tXZzuI7sBfiic7P48aYO4/lwMaYamNMrfN6PuAXkaxj2ecRiUsk3jQBUFbX1G2HVUqp401nawQYY+YB87rqwCLSH9hjjDEiMg0bSmVdtf/D8ifgb24EtEaglHK3QwaBiNQAHTXFCGCMMamH+OzzwEwgS0SKgPtwBqEZY/4AXAH8h4iEgAZgjjN6uXv4E/E1VuERDQKllLsdMgiMMUc9jYQx5muHWf9b4LdHu/9j5k9AmuvpkxhHmQaBUsrF3PnMYgB/EgQbyEiKo1zvGlJKuZiLgyABgvVkpwQoqWmMdWmUUipmXB8EOekJ7KzUIFBKuZd7gyAuCUKN5KTGsaemkWBYp5lQSrmTe4PAnwDA4BTBGNhTrbUCpZQ7uTgIEgHISbZvtXlIKeVWLg4CWyPISbRNQjsrG2JZGqWUihkXB4GtEfRPsEGwo6w+lqVRSqmYcX0QxNPEwPQEtu6tjXGBlFIqNlwcBLZpiGADw7KT2FpaF9vyKKVUjLg3COKS7O/meoZnJ7O1tJbunOpIKaWOF+4NgpYaQXMtw7OTqGsOU6wdxkopF3JvEMSn2d9NNUwe1AeAFV9Uxq48SikVI+4NgoAzg3ZjFWMGpJAY5yV/e3lsy6SUUjHg3iCISwbxQFM1Pq+HKYPTyd9eEetSKaVUt3NvEHg8tlbQWAXA1CEZbNhdTU1jMMYFU0qp7uXeIADbT9ASBHl9iBj4TPsJlFIu4/IgSIXGagCmDO6DR9B+AqWU67g8CNJbawTJAR9jBqSSv0P7CZRS7uLyINjXNARwcl4Gn31Rqc8mUEq5igZBmyA4aUgfGoJh1u+qjmGhlFKqe7k7CAKp0LTvoj81zw4s09tIlVJuErUgEJGnRaRERNYcZL2IyKMiUiAiq0TkxGiV5aDi02wQRMIADEhLIN7v4advrOPlFUXdXhyllIqFaNYI/gzMOsT6C4GRzs9c4PdRLEvHEjPs74Z9NYDLpgwE4LH3tnR7cZRSKhaiFgTGmA+AQ92LeSnwF2MtBtJFZEC0ytOhxEz7u76sddF9Xx7H9dOHsG1vnQ4uU0q5Qiz7CAYChW3eFznLDiAic0UkX0TyS0tLu64ELUFQt7d1Ubzfy4Xj+xOOGL2VVCnlCj2is9gY87gxZqoxZmp2dnbX7Tgpy/6u39tu8YTcNERgdVFVBx9SSqneJZZBUAwMavM+11nWfTpoGgJIifczNCuJ1cUaBEqp3i+WQfAa8HXn7qHpQJUxZle3lqC1aajsgFUTBqaxcN0eHn5nU7cWSSmluls0bx99HvgUGC0iRSJyk4jcIiK3OJvMB7YCBcATwLeiVZaD8gXsWIL9moYAbjp9KAAfFxy4TimlehNftHZsjPnaYdYb4NZoHb/TEjMOaBoCmJibzlVTc3lvYxd2Tiul1HGoR3QWR1VSX6jZ3eGqIZlJlNQ08cwn27u3TEop1Y00CPrkQcWODlflZSYBcN9ra1m3U+cfUkr1ThoEGUOhqhBCTQesystKbH09T6ecUEr1UhoEGcMAA5VfHLBq7IBUnvz6VM45oS//WFlMtY40Vkr1QhoEfezdQZRvO2CViPClsf2Yc/Ig9tY2M/G/FugU1UqpXkeDIGOY/V2+9aCbzBzdl0sm5QDwvRc/p6z2wGYkpZTqqTQIkrIgLhkqDqwRtIjzeXj0a1P40zdOZmtpLTc9k09zSJ9ippTqHTQIRGzzUAdNQ/s7e3Rffnn5RFYWVjJvRRGNwXA3FFAppaJLgwDsnUOHaBpq66KJdqbsu19ezc/eWBfNUimlVLfQIAAbBJU7Wp9Udih+r4eLJtgweP3znQA0hbRmoJTquTQIADJHQLgZKrZ3avNfXTGRr00bTHVjiKv+8Cmj7/knb63u3vnylFKqq2gQAOQ4j0suXt6pzZMCPmaN7w/A0u32IWyPvLsZO32SUkr1LFGbdK5H6TvG3jlUuBQmXtWpj5w+IotfXTGRPolxlNU2cdfLq/nD+1s5b2w/mkMRxuakRrnQSinVNaSn/RU7depUk5+f3/U7fuYSqC2BWxcf8Udrm0KMv+/tdste//bpTMhN66rSKaXUMRGR5caYqR2t06ahFidcDKXrYc+R3wmUHPDx318Z327ZD+atIhTWsQZKqeOfBkGLcZeBeGDty0f18eumD+HDH5zN3DOH8cicyazfVc1tf1tJcWUD85YXaf+BUuq4pX0ELZKzYdApsOltOOeeo9rFoIxEfjh7DACF5fX8z4JNfLJlLxX1QXZXN3Lr2SO6ssRKKdUltEbQ1sjzYfeqgz6o5kjcfNZwhmUlUVFvZyydt1ynsVZKHZ80CNrKO93+7uRtpIfi93r40UW2dnDGyCy27q3jvn+s4cVlhce8b6WU6koaBG31GwcI7F7dJbs7d0w/Pr7rHO778lgAnvl0Bz+Yt4oJ971NSU1jlxxDKaWOlQZBW3FJdpTxrlVdtsuB6QmM6JvCm985nU/uOofh2UnUNIV4cMEm9lQ3UlheT0Vdc5cdTymljpR2Fu8vZwpsXgB1ZZCU2WW7HZdjxxS8872zGH/f2/xtWSF/a9NM9KcbT+asUdl4PNJlx1RKqc6Iao1ARGaJyEYRKRCRuzpYf6OIlIrISufnm9EsT6ec/l1oroN/3hmV3YsID1w+kcumDGy3/Bt/XsYtzy3X20yVUt0uaiOLRcQLbALOA4qAZcDXjDHr2mxzIzDVGPPtzu43aiOL21r0ALz/C7hpIQyaFrXD/G3pF3y6tYx7Lx7Lva+t5c1Vu0hP9HPdKUOYNCgdgPPG9ova8ZVS7nGokcXRbBqaBhQYY7Y6hfgbcClw/E/if+q34aMHYe2rUQ2COdMGM2faYAAeumoygzMSWbShhN8uKmjd5qVbZjA1L4PmUITtZXUMzUrC79WuHaVU14nmFWUg0PZeySJn2f4uF5FVIvKSiAzqaEciMldE8kUkv7S0NBplbS+QAsNmwvrXIRyK/vGwj8O8c9YJvHXbGfz+2hPJSIoDYO6zy3nsvQK+//fPOf+hD7j+qSWEI9p8pJTqOrH+0/J1IM8YMxFYCDzT0UbGmMeNMVONMVOzs7O7p2Qn3gBVX8Bnz3bP8RwiwoUTBrD8ni/xzvfOJCs5jl/9cyOvOQ/BWby1nMc/2MrnhZV885l85jz+abs5jRqaw/qgHKXUEYlmH8EM4L+MMRc47+8GMMY8cJDtvUC5MeaQU3Z2Sx8BgDHwxDm24/jWJfbZxjFgjOHTrWXcOW8VD189mSc/3MZba9qPfD5tRCbFFQ1cNHEAL+YXUVrThN8rfHznOfRNjY9JuZVSx5dYzT66DBgpIkNFJA6YA7y2X8EGtHl7CbA+iuU5MiJw0g2wdyP8ergNhJgUQzh1eBYf3HE2Jw3J4OeXTWhd9/Fd53Dr2cPZtKeW7WX1/G7RFkprmgAIhg2zHvmQbXtjU26lVM8R1ecRiMhs4GHACzxtjPm5iPwUyDfGvCYiD2ADIASUA/9hjNlwqH12W40AoKkW/jwbdn0OF9wPSdkw4cqY1Q5aFJbXEwxHGJad3Lrsn2t2c8tzB06NMS4nlZvPGs6AtHhCYUNNY5BnF+8g4PMSDEf45hlDmTgwnbREf3d+BaVUNztUjUAfTHM4xsDvTrE1A4Dr5sGIL3Xf8TspFI7w0vIizhvbj4Xr9jB9WCbvbyrlvtfWHrCt1yPtOpz7pQa4/fzRXHlSLhLjkFNKRYc+mOZYiMDsX+97/6+fQ0NF7MpzED6vhznTBpOZHGDOtMHkZSVxw6l5XDIpp912d1wwmt9fe2K7ZXuqm/jBS6v49vOfsXRbOef8z3v8ZsFGIk5YFFc28MNXVlOuU2Eo1StpjaCzqoqhcDG8fLOdhuLGN8AX6P5yHCFjDNUNIZ75dDvfOC2PlHg/TaEwd/x9FScMSGH9rhpe/3wnX5mcw2uf72T/O1N/c+UkXl+1k/c2lnLSkD78+oqJ9E2NJznga92/iFBe10xagh+vTpGh1HFJm4a60tpX4O83wpTrbU3BnxC7snSR0pomslMC7Cir48X8QqYM6sPOqgbun7+exqC9NdXnEUJOSsT7Pdx46lDOGpXNd/72GV+ZnMNTH21jxvBMfnn5RHL7JMby6yilOqBB0NVevRVWPgcTr4ZTboGEdMgYFtsyRUFJdSM/enUNCX4vD141iR3l9Ty4YBNflNezuriqw8+kBHy8cuupbNxdS2VDM89+uoMbT83jrNHZDEizoWmMYd2uasYOSG3tk9hSWsvA9ATi/d7WYFJKdR0Ngq4WicBr/2nDAMCfCD/aFdsydbO/fLqdxxZtYUJuGgvX7eHBqyZRXNHAbxZuOuhnfnbpOCrrg5TWNvGXT3dwxwWjaQqGGZuTxi3PLSc13sfgzETWFFfz0NWT+OP7W/n1FZMormxg+rAM0hPtaOtl28sZnJFIPx0joVSnaRBEQ2UhPDx+3/sfbIPEjNiVJwaMMTQGI3ywuZTzx/ZDRLjpz8t4d0MJYDumbzp9KK98VszjH2w9qjENLU1So/ul8NZtZ9AQDDPuvrdJjffx8rdOJT0xjqxkW3t4YP56VhdXcf9lE8jLSurS76pUT6dBEC0b5sOHv4HifEjJgTEX26aizOGxLlnMfLCplK8/vZTfXjOFiyfuu2OpujHI9174nPPG9uXkvAx2VTVy7ZNLALjmlMF8uLmUwvKGozrmI3Mmk7+9gmcX72hddv9lE3hu8Q4mDEzj4kkDKCipZU91E9WNQW4/bxTN4Qi7qxqZMrhPu32FI4aVhRWsKqoiHDHccGqeTvKnegUNgmhb8zK8/ysodQZGx6fBuffC+Cts/4HL7KxsICf98J3o/1yzm/REP9OHZRIKR1i6vZzEOB+fbNnLgrV7uHPWCXywuZQZwzJZWVjJZ19UsGijnXQw3u9p7cgO+Dw0hezrYdlJbC21NY+kOC8iQm1T+4kDx+WkUlkfpLiygblnDuO6U4YwONN2cP91yQ5+9MqadtvPPXMYN585jGufXMKPLhrDGSO7ab4rpbqQBkF32fIvWHgf7HYedRlIhSuetmMRhp8b8xHJvcGmPTVU1DUzbWgGxsD989fz5EfbWte/8Z+ns25nNS/kF/Ltc0YwY1gmf/p4Ow8t3ERzOEJWcoCqhmaC4X3/7tMS/Dzzb9NIDvj46mMfU90Y4vHrT2Lus/tGan9r5nAee28LiXFeFn1/Jp99UYGIMHN0NgGft3W7irpmXl+1k5PzMhgzIJWCklqyUwKkJRx85HYkYhDhsIP5dlc10j9N+0XU0dEg6G7L/wyv39Z+2Sm3wIW/jElxerO9tU1c+MiHnNA/hUsm5XDFQUZHG2N4aXkRM0f3ZfmOCh5+ZxM/nD2GyoYg33n+s3bbfmvmcH4w6wTy7nrzsMeP93u4fvoQlm6v4KyRWRRVNvDyimLi/R6+emIuLy4rJCMpjhdunsH7G0tYsq2cn182gY8L9vLspzvonxbPog0l3HBqHt+/YDTb9tbx2RcVjOibzMTcdBqaw7y/qYTUBD/XPLGER+ZM5tLJHc3mfnC7qhqoawoT5/W01nyU+2gQdLdIBAqXQLgJ/m8OiAeCdTD2KzBgIpxxe6xL2KtEIoZQxBDnO7q2/Fv/bwWb99QwY1gmE3LTuWBcP1Li/by9djfLd1QwY1gm63ZVc9XUQbz++U6KKxs4f2w/9tY287tFBazbVU1KwEeN0wQ1fVgGVQ0h1u+qJis5QGV9c+sYDGjfrNUi4PPwHzOH88i7mzEGPAJjc1JZU1wNQFZyHHtrmxmYnsA1pwwmOznAlMHpNIUi+L0e7p+/nlnj+1NZH2RPdSP3XDSGJdvKSQ74uOmZZeyttaPC/++bp3DqiKyjOk+qZ9MgiKVQE9SVwpPnQY19pgAjzoPzfgob34Rpc+3kdqk52nTUAzUGwyzeWsa4nDSqGpp55bNirps+hKxkO0BveHYyH2zey49fXcP0YRlcN30I//n8Z+woq+exa09k6bZyvjwph2/8aSnVjSHGD0zlV5dP4qo/fnpA3wa07w85lDifh+YOtktL8NMvNcDQrCROHZ7FJ1v20icxji2ltVx+Yi5zpg3msy8q+GRLGe9tLGFUvxROGZbJkx9uZe6ZwzhzVDbJcT48nRhBbozhn2t2c/YJfYn3e9laWktjMMKYASk0BiMkxHkPuw/VdTQIjgeRCESC9i6jD38DEed/8qxRsHcT5J0BX/oJ5J4U23KqqGsMhvmivJ5R/VJal1XUNbN2ZzUnDkknMc7Ho+9u5sGFm3jrtjPwez3cOW8VV55kL9RNoTArdlSyu7qBPdVNfLCplEsn59A3NR6/x8N1T9m7sX526TgWrNvDh5v38uVJOXxRVsfnRVX0TQkQjhjK2swdNTA9geLKBsYMSGX9ruoOy50c8OH1CGMHpHL/VycwMD3hgFpYcWUDP351DburGimsqKem0f47v376kNa7uiYPSqeyvpk7LjiBBet2MyQzif6p8USMYXdVI9OHZfJFeT2lNU2cOSqLKYP7tE5l8v6mUjbsquam04fiEaE5HOHjgr2cOSobv9fDi/mFJMX5uGiineG+5XNH+t9nVVEV04b2rtvBNQiONwXvQMG74PXDx4/YZd44CDfDpGtg4Il2htOqQsgcCakDDr0/1etEIobiygYGZRx5m/7ba3eTEvBx6ogswhFDYXk9eVlJBMMRCsvrGZyRSDBseH9TCWkJccT5PEzKTeN/FmziyQ+34vUIT994Mo3BMLVNIVYWVnLtKYO57HeftDZ/tRiQFk/A52FoVhIG+Gjz3nbNYF3hmlMG88bnOxmbk8rireUAnDkqm8Ly+nZjU1qazwCe+bdpLN9ezv8tLeRr0waxbHs5BSW1TBiYxuaSWqYPy+SrUwZSVtfM1Lw+fFxQxvId5Xy6pYztZfUAXD11EN87fxTZyYF2NaD65hA/f3M955zQl3PH9KO+OUR1Q4iyuiaaQhG+KKvn/HH9SIzb90j4plCYDzbtZcLAtNYOf2MMu6oa6Z8a37r/xqDty1m8rYzUeD/jB+57TldZbROZyUc/4l6D4Hi28S3IHGGbkJ78EmAg1LhvfVI23LoUGqvARFw9RkFFX3ldM1UNQYZ2MCBv6bZydlU1MDw7mZ+9sY4l2+xFedrQDCrqmhGB00Zkcc20wSzZVs49r+67Dfeei8bwrw0lDM9OZvKgdB57r4A91U2tzV9/v2UGxRUNLFi3m+qGEN+/YDSLt5bxi7c24PMIyfE+KuuDAIzsm8zmktrWWkxbyQFfh01qAKP7pVBQWktOeny7MSuTB6WzsrASEdv01rb/ZlBGApGIrelMHpSOzyPk79g3+/Clk3NYvqOCoor25Th/bD/OG9uPsTmpVDUE+dkb61m/q5opg9MZmpnEquIqCkpqW7dPjfcxIC2BrXtrGdk3hXVOrWzbA7MB+6CpGQ+8yxUn5XL37DEH+893SBoEPUWw0c5ouuVd+PxvsPU927/QVtpgOP02+8Q0XwL0nwBDZtipsf2JPWJGVNXzVTcGeWjhJv7ttKEHrbWUVDcSH+fFK0JSwNduXct15+OCMjKS4hibk9rhPnZWNtDPaTYa+aO3ANh6/2x2VzfSNyXAnMcXMzE3nbNGZxPweZiYm8Z/v7meSblpnDkqm8Vby1iwdg9fn5HX2tTjEXhhWSHPLdnR2hmfkxbPEzdMJSXg58xfL+LrM4awsrCSVUUdz6kFkJ0SaH0i4LCsJK6dPoShWYnMW17Mm6vbTznTJ9FPnM/Dnmq7fVKcl7rmA58t3j81nt3V+/4Q9Hul3a3OT984lXNO6HfQMh2KBkFPVvAOfP6CbS6qL4dNb8Hu1e238cXbWkTqQJh5Fww6Bfastc1LHh/E6S2DqucrKKkBhBF9kw+7bWc9tHATf/p4Gy/cPIMxA2wYNYcixPk8NAbDvLVmF1OHZJAc8NEnKQ5jDEPvnk96op+F/+8sqhqaGZie2K7j2xjDmuJq6ptDbC+rIz0xjtNHZLFtbx0X/+9H/ObKSVx+Ui6riioJhiPUN4epbw4zLieV3D6JPLt4B3/PL6RvSoB31pe07jfg87D2JxfgO8qR7hoEvUkkbEcxR4Iw8nzYvMB2Nq9/vePtPT77eM2zf2Sbn976AQw/B8Z8GZKy7K2tkRAEnI7Lih3wwa/h9P+nzVDKFY60Q3lPdSNej7TOcXUk6ptD7foODicSMXxYsJdhWUn4vZ5jGlCoQeAGkQhseAMSM2Hty/ain5Buf3/2HATrD/35vmOhuRYqv7Dvh5wOJ91gaxcYEC8k97VNTw2VUF0M2SeAR28BVKonOFQQdD6a1PHN44Gxl9jXeae1Xzfuq/CPW2H0hbZ2UFdqQyOpr71TyYRh6/vgT7IX/sEz4OOHYcdH7ffjT7I1h9rd9v3IC2D6LXYqjYJ3YPB0KNtiw2LClbD2Vdj8NvSfaENj1AV2rESwwYbT+MshPt0ua6qBeKeduLF632ulVNRpjUB1bNMCqNhmL9DJ/ewdS0XLbNNU1kh7Mf/4ETt6uiMev22+amvI6VC/1w6gqy6yy8QDxgDGdoTHJUHpBmegXY0NranfsH0ggTToOwbe/wVU77LBM/6rsHqerf0MmAz1ZbZ8Xj8svNc2gY2ebfeZ3N8eb/mfIGO4DSKP095qjP3xeGztyoTtPsq3QWOl3XfFdkjLtcsBavZAQh/wxe37jpHIvn0eD+rLbRl1sKLradOQio7metjwpq0NzLwLipfbDutgHaz7B+ScCGMvtbe+LvkjLHsC0gfbYEnMtOESl2yfBT3oFNi80NYEWpqnAqm26amh4sBjZ4/ZN9trR1rGZYC9uyrUwRTXfYba5rD4dLttVaHteG9pRkvqC3VOZ11qrg2vxEwbIM11sOoFSB8CI861t/mGmmDpEzDhChuCI75k7/5KGWADbONb0G8cnHAxYOxFunQ99JtgA6Z0vQ1QETuDbfk2p3xpNqT8CfZcrJkHJ37dHtvjs0/HE7H9RbV7YMhpMGiareX95RI7E+4Zt0NdmQ1KjxfCQfv8jKRsO1li1kj732Z/kYg9pi/O/hHQ2dl0jbHHaBuSbYVDNpQ7E5qRCM6sfJ079sE0VNh/F3ExeFZF+Tao2W3v8AN7fro5nGMWBCIyC3gE8AJPGmN+sd/6APAX4CSgDLjaGLP9UPvUIOjBwsF9f00fSiRiayOpA21NYPcqe7Fuqra1kj5DYdxX4IvF9v3wc2DLIju/k8cL/cZDbYmtLWz/0N5BNeQ05wIYgn5jbdisedl2mNfsthcIsHdk1e6x/5PmTLH7qiu1F/Ehp8Kuz205AAafakOvdFPHQRNLfYZC5Q4btmAv8i0B21YgDZqq7EU5a7TtBwqk2O9YX2FrcDXOrZDisSPgRWxgeePs64YKqN5pmybLtkD5Vhtytbth6Fm2SXL3ahvsoQbY+Zl9Lx5bW+s/ERrKbbiCDbcBE21TpNcP7z0AiN2/L2CbHLNG2prlF4tt7S3UZAMxZ7L9d9Z/vC1DS7DHJcOKZ2yYnTDbPj+kqshO7VK7216o68shbaDtL+s/wQZvsMGG98ePwpRr7R8CdXvtHw3VzpQxmcPtHw0enw2ZLf+yN3LUlcKyJ+1/h53OxIZn3WX71zYvgFGz7L5DTfazoy6ArYvAG4BAsv0+/iT7R8qKv9j/liO+BKPOP6p/EjEJAhHxApuA84AiYBnwNWPMujbbfAuYaIy5RUTmAJcZY64+1H41CFTU7f/XmjHOxSQJ9hbYi1nqwH1PpAs1AwZ2fAIp/e1dWL4EW1NKyrJBtXkhZI+2YVSywYZN7W67zhuwF8++Y+xnvXFQutHWKhKz7MW5uc5+trke0gdBVbG9SNaX2SADe1HJmQz5T9vaWdZoGHYWLHrAlnXwdFsba6q2F8TCJTZIJ19nm/j2rLMXr+Y6+139CbYGMNC5dlR+YR/C1Fhlm+YCKbas8Wn28xXbbUB4vDYAMobZvqCmKkDsOUrMtJ/LPdnup3iFDRuPf984mFCT85mD6DvWfv9gva1B1pfZ5bnT7EU23Gy/h8dvL56mzf36LcdpCT8TsRdhf5KtlVUVHfrYRyMuGfrk2T9IOIbrrXhh5t1w1h1H9/EYBcEM4L+MMRc47+8GMMY80Gabt51tPhURH7AbyDaHKJQGgVLHoUjYXpg9fluLa2lCaq63NYr0Ifbi3NF0KU21zsU4ft++yrfav+xNxF6g45LsRbqxCgZM2lfT8Xjt56sKbZCCDe7aEhtQLbdH791o+4XiU51mK6fZMNjgbOcEf3OdXVexwwZI2VZbI514lb2Qi8cGZFyyDbSqIqeG5LOB3lABiX1skKfl2jDsP2HfsYqW2XORkG4DPC7Jhlp8mg3mQLKtrfjjoXCpraWYCEyaY8M8of0T9Y5ErILgCmCWMeabzvvrgVOMMd9us80aZ5si5/0WZ5u9++1rLjAXYPDgwSft2LEDpZRSnXeoIDiObm84OGPM48aYqcaYqdnZ+phApZTqStEMgmJgUJv3uc6yDrdxmobSsJ3GSimlukk0g2AZMFJEhopIHDAHeG2/bV4DbnBeXwH861D9A0oppbpe1EYWG2NCIvJt4G3s7aNPG2PWishPgXxjzGvAU8CzIlIAlGPDQimlVDeK6hQTxpj5wPz9lt3b5nUjcGU0y6CUUurQekRnsVJKqejRIFBKKZfTIFBKKZfrcZPOiUgpcLQjyrKAvYfdyn30vBxIz8mB9Jx0rKeclyHGmA4HYvW4IDgWIpJ/sJF1bqbn5UB6Tg6k56RjveG8aNOQUkq5nAaBUkq5nNuC4PFYF+A4peflQHpODqTnpGM9/ry4qo9AKaXUgdxWI1BKKbUfDQKllHI51wSBiMwSkY0iUiAid8W6PN1FRJ4WkRLnIUAtyzJEZKGIbHZ+93GWi4g86pyjVSJyYuxKHj0iMkhEFonIOhFZKyK3Ocvdfl7iRWSpiHzunJefOMuHisgS5/u/4MwmjIgEnPcFzvq8mH6BKBIRr4h8JiJvOO971TlxRRA4z0/+HXAhMBb4moiMjW2pus2fgVn7LbsLeNcYMxJ413kP9vyMdH7mAr/vpjJ2txBwuzFmLDAduNX59+D289IEnGOMmQRMBmaJyHTgl8BDxpgRQAVwk7P9TUCFs/whZ7ve6jZgfZv3veucGGN6/Q8wA3i7zfu7gbtjXa5u/P55wJo27zcCA5zXA4CNzus/Al/raLve/AP8AzhPz0u7c5IIrABOwY6a9TnLW/9fwk4xP8N57XO2k1iXPQrnIhf7h8E5wBuA9LZz4ooaATAQKGzzvshZ5lb9jDG7nNe7gX7Oa9edJ6fqPgVYgp6XliaQlUAJsBDYAlQaY0LOJm2/e+t5cdZXAZndWuDu8TDwAyDivM+kl50TtwSBOghj/3Rx5T3EIpIMzAO+a4ypbrvOrefFGBM2xkzG/hU8DTghtiWKLRG5GCgxxiyPdVmiyS1B0JnnJ7vJHhEZAOD8LnGWu+Y8iYgfGwJ/Nca87Cx2/XlpYYypBBZhmz3SnWeKQ/vv7oZnjp8GXCIi24G/YZuHHqGXnRO3BEFnnp/sJm2fFX0Dto28ZfnXnbtkpgNVbZpKeg0REexjUtcbYx5ss8rt5yVbRNKd1wnYfpP12EC4wtls//PSq585boy52xiTa4zJw143/mWMuZbedk5i3UnRjR0+s4FN2DbPH8W6PN34vZ8HdgFBbFvmTdg2y3eBzcA7QIazrWDvrtoCrAamxrr8UTonp2ObfVYBK52f2XpemAh85pyXNcC9zvJhwFKgAPg7EHCWxzvvC5z1w2L9HaJ8fmYCb/TGc6JTTCillMu5pWlIKaXUQWgQKKWUy2kQKKWUy2kQKKWUy2kQKKWUy2kQKNWNRGRmywyWSh0vNAiUUsrlNAiU6oCIXOfMzb9SRP7oTMZWKyIPOXP1vysi2c62k0VksfOsglfaPMdghIi848zvv0JEhju7TxaRl0Rkg4j81RnprFTMaBAotR8RGQNcDZxm7ARsYeBaIAnIN8aMA94H7nM+8hfgTmPMROzI45blfwV+Z+z8/qdiR3iDne30u9hnYwzDzmejVMz4Dr+JUq5zLnASsMz5Yz0BOwFdBHjB2eY54GURSQPSjTHvO8ufAf4uIinAQGPMKwDGmEYAZ39LjTFFzvuV2OdFfBT1b6XUQWgQKHUgAZ4xxtzdbqHIj/fb7mjnZ2lq8zqM/n+oYkybhpQ60LvAFSLSF1qfZTwE+/9Ly4yT1wAfGWOqgAoROcNZfj3wvjGmBigSka84+wiISGJ3fgmlOkv/ElFqP8aYdSJyD7BARDzYmVtvBeqAac66Emw/Athph//gXOi3At9wll8P/FFEfurs48pu/BpKdZrOPqpUJ4lIrTEmOdblUKqradOQUkq5nNYIlFLK5bRGoJRSLqdBoJRSLqdBoJRSLqdBoJRSLqdBoJRSLvf/AZ7aIIqasA4hAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "RBkmDeUW9hE4"
      },
      "outputs": [],
      "source": [
        "# Loading the saved model\n",
        "model = tf.keras.models.load_model(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxvb2Y299hE3",
        "outputId": "7015e279-0501-4f24-d1b5-90652d2de17d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Model evaluation\n",
        "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFz9Tb0I9hE4",
        "outputId": "bb8a62a9-bf7d-4d99-8099-bda4e2e1c73a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 133ms/step\n",
            "[2.76006440e-09 9.93047059e-01 2.48687429e-04 3.26117970e-07\n",
            " 4.84285265e-04 6.18812488e-03 1.08997555e-14 1.76566406e-08\n",
            " 8.12905569e-07 6.10974303e-06 4.35375034e-17 6.77406604e-14\n",
            " 1.19578814e-09 6.44611991e-17 9.36594552e-06 9.86357263e-12\n",
            " 1.24409198e-05 9.20272498e-07 9.98823566e-07 8.51285152e-18\n",
            " 1.27166640e-14 1.18175894e-14 7.53322638e-07 8.33084093e-15\n",
            " 1.74167226e-11 7.36794862e-14]\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "# Inference test\n",
        "predict_result = model.predict(np.array([X_test[0]]))\n",
        "print(np.squeeze(predict_result))\n",
        "print(np.argmax(np.squeeze(predict_result)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3U4yNWx9hE4"
      },
      "source": [
        "# Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "AP1V6SCk9hE5",
        "outputId": "efce96b9-ca1c-44a5-ef77-58f1d5fc154c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19/19 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 504x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        49\n",
            "           1       1.00      1.00      1.00        52\n",
            "           2       1.00      1.00      1.00        49\n",
            "           3       1.00      1.00      1.00        15\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      1.00      1.00        25\n",
            "           6       1.00      1.00      1.00        16\n",
            "           7       1.00      1.00      1.00        25\n",
            "           8       1.00      1.00      1.00        13\n",
            "           9       1.00      1.00      1.00        24\n",
            "          10       1.00      1.00      1.00        19\n",
            "          11       1.00      1.00      1.00        17\n",
            "          12       1.00      1.00      1.00        26\n",
            "          13       1.00      1.00      1.00        25\n",
            "          14       1.00      1.00      1.00        18\n",
            "          15       1.00      1.00      1.00        16\n",
            "          16       1.00      1.00      1.00        15\n",
            "          17       1.00      1.00      1.00        14\n",
            "          18       1.00      1.00      1.00        39\n",
            "          19       1.00      1.00      1.00        25\n",
            "          20       1.00      1.00      1.00        27\n",
            "          21       1.00      1.00      1.00        10\n",
            "          22       1.00      1.00      1.00        20\n",
            "          23       1.00      1.00      1.00        18\n",
            "          24       1.00      1.00      1.00        12\n",
            "          25       1.00      1.00      1.00        18\n",
            "\n",
            "    accuracy                           1.00       603\n",
            "   macro avg       1.00      1.00      1.00       603\n",
            "weighted avg       1.00      1.00      1.00       603\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def print_confusion_matrix(y_true, y_pred, report=True):\n",
        "    labels = sorted(list(set(y_true)))\n",
        "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    \n",
        "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
        " \n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
        "    ax.set_ylim(len(set(y_true)), 0)\n",
        "    plt.show()\n",
        "    \n",
        "    if report:\n",
        "        print('Classification Report')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print_confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNP6aqzc9hE5"
      },
      "source": [
        "# Convert to model for Tensorflow-Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ODjnYyld9hE6"
      },
      "outputs": [],
      "source": [
        "# Save as a model dedicated to inference\n",
        "model.save(model_save_path, include_optimizer=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRfuK8Y59hE6",
        "outputId": "106250fb-84e1-4ee8-bc8e-dcedb2bfd31c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\LETUAN~1\\AppData\\Local\\Temp\\tmpycr419q_\\assets\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "11336"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transform model (quantization)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quantized_model = converter.convert()\n",
        "\n",
        "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHBPBXdx9hE6"
      },
      "source": [
        "## Inference test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mGAzLocO9hE7"
      },
      "outputs": [],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "oQuDK8YS9hE7"
      },
      "outputs": [],
      "source": [
        "# Get I / O tensor\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "2_ixAf_l9hE7"
      },
      "outputs": [],
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4FoAnuc9hE7",
        "outputId": "330d050b-a3fb-41ce-fa07-dc7a48d715e7",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Inference implementation\n",
        "interpreter.invoke()\n",
        "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vONjp19J9hE8",
        "outputId": "9338c9f1-499b-4e10-844d-950075e98a75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2.8617657e-09 9.9234504e-01 2.5088721e-04 3.0812853e-07 5.2478071e-04\n",
            " 6.8482473e-03 8.8365476e-15 1.4936036e-08 8.4096172e-07 5.7572329e-06\n",
            " 3.3410612e-17 6.1055205e-14 9.9678321e-10 4.9176175e-17 9.3642166e-06\n",
            " 9.0988753e-12 1.2377941e-05 7.8187054e-07 9.4735185e-07 7.5567300e-18\n",
            " 9.6322427e-15 9.2191718e-15 6.2984412e-07 6.8019672e-15 1.8738426e-11\n",
            " 5.8576848e-14]\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "print(np.squeeze(tflite_results))\n",
        "print(np.argmax(np.squeeze(tflite_results)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Keypoint_model_training.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 ('.mtao': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "8c605ef64628d116b4b885575680aefdda046457c284ed018b9a1bcba7734ddc"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
